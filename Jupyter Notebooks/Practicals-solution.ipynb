{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Tutorial: Spam Filtering with Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Agenda\n",
    "\n",
    "2. Representing text as numerical data\n",
    "3. Reading a text-based dataset into pandas\n",
    "4. Vectorizing our dataset\n",
    "5. Building and evaluating a model\n",
    "6. Comparing models\n",
    "7. Examining a model for further insight\n",
    "9. Tuning the vectorizer (challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 1: Representing text as numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# example text for model training\n",
    "simple_train = ['call you tonight', 'Call me a cab', 'please call me... PLEASE!']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    "\n",
    "> Text Analysis is a major application field for machine learning algorithms. However the raw data, a sequence of symbols cannot be fed directly to the algorithms themselves as most of them expect **numerical feature vectors with a fixed size** rather than the **raw text documents with variable length**.\n",
    "\n",
    "We will use [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) to \"convert text into a matrix of token counts\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# import and instantiate CountVectorizer (with the default parameters)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learn the 'vocabulary' of the training data (occurs in-place)\n",
    "vect.fit(simple_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cab', 'call', 'me', 'please', 'tonight', 'you']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the fitted vocabulary\n",
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x6 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 9 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform training data into a 'document-term matrix'\n",
    "simple_train_dtm = vect.transform(simple_train)\n",
    "simple_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 1, 1],\n",
       "       [1, 1, 1, 0, 0, 0],\n",
       "       [0, 1, 1, 2, 0, 0]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert sparse matrix to a dense matrix\n",
    "simple_train_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    0     1   0       0        1    1\n",
       "1    1     1   1       0        0    0\n",
       "2    0     1   1       2        0    0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(simple_train_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    "\n",
    "> In this scheme, features and samples are defined as follows:\n",
    "\n",
    "> - Each individual token occurrence frequency (normalized or not) is treated as a **feature**.\n",
    "> - The vector of all the token frequencies for a given document is considered a multivariate **sample**.\n",
    "\n",
    "> A **corpus of documents** can thus be represented by a matrix with **one row per document** and **one column per token** (e.g. word) occurring in the corpus.\n",
    "\n",
    "> We call **vectorization** the general process of turning a collection of text documents into numerical feature vectors. This specific strategy (tokenization, counting and normalization) is called the **Bag of Words** or \"Bag of n-grams\" representation. Documents are described by word occurrences while completely ignoring the relative position information of the words in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the type of the document-term matrix\n",
    "type(simple_train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 2)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 3)\t2\n"
     ]
    }
   ],
   "source": [
    "# examine the sparse matrix contents\n",
    "print(simple_train_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    "\n",
    "> As most documents will typically use a very small subset of the words used in the corpus, the resulting matrix will have **many feature values that are zeros** (typically more than 99% of them).\n",
    "\n",
    "> For instance, a collection of 10,000 short text documents (such as emails) will use a vocabulary with a size in the order of 100,000 unique words in total while each document will use 100 to 1000 unique words individually.\n",
    "\n",
    "> In order to be able to **store such a matrix in memory** but also to **speed up operations**, implementations will typically use a **sparse representation** such as the implementations available in the `scipy.sparse` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# example text for model testing\n",
    "simple_test = [\"please don't call me\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "In order to **make a prediction**, the new observation must have the **same features as the training observations**, both in number and meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data into a document-term matrix (using existing vocabulary)\n",
    "simple_test_dtm = vect.transform(simple_test)\n",
    "simple_test_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    0     1   1       1        0    0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(simple_test_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "**Summary:**\n",
    "\n",
    "- `vect.fit(train)` **learns the vocabulary** of the training data\n",
    "- `vect.transform(train)` uses the **fitted vocabulary** to build a document-term matrix from the training data\n",
    "- `vect.transform(test)` uses the **fitted vocabulary** to build a document-term matrix from the testing data (and **ignores tokens** it hasn't seen before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 3: Reading a text-based dataset into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# read file into pandas using a relative path\n",
    "path = 'data/spam_ham.csv'\n",
    "spam_ham = pd.read_csv(path, header=0, names=['label', 'location','message'])\n",
    "spam_ham.drop('location', axis=1, inplace=True)\n",
    "spam_ham.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30974, 2)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the shape\n",
    "spam_ham.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>LUXURY WATCHES - BUY YOUR OWN ROLEX FOR ONLY $...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Academic Qualifications available from prestig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Greetings all. This is to verify your subscrip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>try chauncey may conferred the luscious not co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>It's quiet. Too quiet. Well, how about a straw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>It's working here. I have departed almost tota...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spam</td>\n",
       "      <td>The OIL sector is going crazy. This is our wee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spam</td>\n",
       "      <td>Little magic. Perfect weekends.http://othxu.rz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ham</td>\n",
       "      <td>Greetings all. This is a mass acknowledgement ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hi, L C P A X V V e I r m a A I v A o b n L A ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0  spam  LUXURY WATCHES - BUY YOUR OWN ROLEX FOR ONLY $...\n",
       "1  spam  Academic Qualifications available from prestig...\n",
       "2   ham  Greetings all. This is to verify your subscrip...\n",
       "3  spam  try chauncey may conferred the luscious not co...\n",
       "4   ham  It's quiet. Too quiet. Well, how about a straw...\n",
       "5   ham  It's working here. I have departed almost tota...\n",
       "6  spam  The OIL sector is going crazy. This is our wee...\n",
       "7  spam  Little magic. Perfect weekends.http://othxu.rz...\n",
       "8   ham  Greetings all. This is a mass acknowledgement ...\n",
       "9  spam  Hi, L C P A X V V e I r m a A I v A o b n L A ..."
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the first 10 rows\n",
    "spam_ham.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam    19280\n",
       "ham     11694\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the class distribution\n",
    "spam_ham.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# convert label to a numerical variable\n",
    "spam_ham['label_num'] = spam_ham.label.map({'ham':0, 'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>LUXURY WATCHES - BUY YOUR OWN ROLEX FOR ONLY $...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Academic Qualifications available from prestig...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Greetings all. This is to verify your subscrip...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>try chauncey may conferred the luscious not co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>It's quiet. Too quiet. Well, how about a straw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>It's working here. I have departed almost tota...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spam</td>\n",
       "      <td>The OIL sector is going crazy. This is our wee...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spam</td>\n",
       "      <td>Little magic. Perfect weekends.http://othxu.rz...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ham</td>\n",
       "      <td>Greetings all. This is a mass acknowledgement ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hi, L C P A X V V e I r m a A I v A o b n L A ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  label_num\n",
       "0  spam  LUXURY WATCHES - BUY YOUR OWN ROLEX FOR ONLY $...          1\n",
       "1  spam  Academic Qualifications available from prestig...          1\n",
       "2   ham  Greetings all. This is to verify your subscrip...          0\n",
       "3  spam  try chauncey may conferred the luscious not co...          1\n",
       "4   ham  It's quiet. Too quiet. Well, how about a straw...          0\n",
       "5   ham  It's working here. I have departed almost tota...          0\n",
       "6  spam  The OIL sector is going crazy. This is our wee...          1\n",
       "7  spam  Little magic. Perfect weekends.http://othxu.rz...          1\n",
       "8   ham  Greetings all. This is a mass acknowledgement ...          0\n",
       "9  spam  Hi, L C P A X V V e I r m a A I v A o b n L A ...          1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that the conversion worked\n",
    "spam_ham.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30974,)\n",
      "(30974,)\n"
     ]
    }
   ],
   "source": [
    "# how to define X and y (from the SMS data) for use with COUNTVECTORIZER\n",
    "X = spam_ham.message\n",
    "y = spam_ham.label_num\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23230,)\n",
      "(7744,)\n",
      "(23230,)\n",
      "(7744,)\n"
     ]
    }
   ],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=427)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 4: Vectorizing our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# instantiate the vectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learn training data vocabulary, then use it to create a document-term matrix\n",
    "vect.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161925"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the fitted vocabulary\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform training data into a 'document-term matrix'\n",
    "X_train_dtm = vect.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# equivalently: combine fit and transform into a single step\n",
    "X_train_dtm = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<23230x161925 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2305787 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the document-term matrix\n",
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7744x161925 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 744528 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 5: Building and evaluating a model\n",
    "\n",
    "We will use [multinomial Naive Bayes](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html):\n",
    "\n",
    "> The multinomial Naive Bayes classifier is suitable for classification with **discrete features** (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# import and instantiate a Multinomial Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40 ms, sys: 0 ns, total: 40 ms\n",
      "Wall time: 38.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using X_train_dtm (timing it with an IPython \"magic command\")\n",
    "%time nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98476239669421484"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2967,    7],\n",
       "       [ 111, 4659]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      2974\n",
      "          1       1.00      0.98      0.99      4770\n",
      "\n",
      "avg / total       0.99      0.98      0.98      7744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00000000e+00,   1.00000000e+00,   1.73677105e-31, ...,\n",
       "         1.00000000e+00,   1.00000000e+00,   7.77424439e-01])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predicted probabilities for X_test_dtm (poorly calibrated)\n",
    "y_pred_prob = nb.predict_proba(X_test_dtm)[:, 1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99670526815912608"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate AUC\n",
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 7: Examining a model for further insight\n",
    "\n",
    "We will examine the our **trained Naive Bayes model** to calculate the approximate **\"spamminess\" of each token**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161925"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the vocabulary of X_train\n",
    "X_train_tokens = vect.get_feature_names()\n",
    "len(X_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '0000', '000000', '0000000', '00000000', '000000000', '00000000000000', '000000000000000000000000000000049999999999999e9', '0000000000000000000000000000000500000000000000e9', '0000000000000016666l', '0000000000000017d', '00000000000000e', '000000000000received', '000000000001received', '0000000001d0', '0000000001l0', '0000000010000000004l0', '0000000016', '000000001d0', '00000000message', '00000000x', '00000001', '00000001content', '00000001irdecode', '00000004', '00000010', '00000010pwm', '00000011', '00000049', '0000005', '0000006hz', '000000eb', '000001', '00000100', '00000100shaftencoder', '000001bdaaa0', '000001bdb744', '000001bdcaf3', '000001c642d0', '000001c64310', '000001c64585', '000001c64615', '000001c64641', '000001c6465f', '000001c6468e', '0000020', '0000040', '0000040b', '0000040c']\n"
     ]
    }
   ],
   "source": [
    "# examine the first 50 tokens\n",
    "print(X_train_tokens[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['３ｄバーチャルｓｅｘメーカー', '４名紹介http', '４月度新規メンバー様応援企画パーティー開催予定', '４月２３日', '５月までのようなので興味のある方はお早めに', '５月中週末３人か４人ぐらいで', '５００円分のポイントが完全無料で自動追加されます', '６名のみとなります', 'ａ型', 'ａ美様現在未亡人でいらっしゃいます', 'ｂ９６', 'ｆカップ', 'ｇａｌ誌多数掲載', 'ｇｏｏｄ', 'ｇｒａｎｄｅｅ', 'ｇｒａｎｄｅｅの理念やシステムのご紹介', 'ｇｗこそ出会いのチャンスhttp', 'ｇｗです', 'ｇｗはこういう女の子と過ごしたいっす', 'ｇｗ特典あり', 'ｈなこと大好きな人ばかり', 'ｈな女の子が多いので', 'ｈな欲望や願望を胸に秘め', 'ｈにそんなに興味なかったのと少し怖いのもあるため', 'ｈのお相手しただけで', 'ｈゲームメーカーの決定版', 'ｈ度', 'ｈ目的の出会いも簡単です', 'ｈ８６', 'ｋ村', 'ｍ子様セーリングクルーザーをお持ちで', 'ｍ字開脚オナニーを机の下から盗撮', 'ｍａｉｌでのサポートは２４時間対応です', 'ｎ藤', 'ｏｌ', 'ｐｃ', 'ｐｃから簡単プロフィール作成', 'ｓクラス専門店', 'ｓ子様秘密が条件で', 'ｓｅｘを求めている', 'ｓｅｘを求めているのです', 'ｓｍ', 'ｔ165', 'ｔバックは', 'ｔバックはいていたらおならが左右に分散するのでなんか変な感じですけどね', 'ｔバックを購入しました', 'ｔ島', 'ｔ谷', 'ｗ６２', 'ｙ里様お互いがくつろげるような']\n"
     ]
    }
   ],
   "source": [
    "# examine the last 50 tokens\n",
    "print(X_train_tokens[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.00900000e+03,   3.90000000e+02,   3.76000000e+02, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  3.63700000e+03,   5.30400000e+03,   0.00000000e+00, ...,\n",
       "          2.00000000e+00,   1.00000000e+00,   2.00000000e+00]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes counts the number of times each token appears in each class\n",
    "nb.feature_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 161925)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows represent classes, columns represent tokens\n",
    "nb.feature_count_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2009.,   390.,   376., ...,     0.,     0.,     0.])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of times each token appears across all HAM messages\n",
    "ham_token_count = nb.feature_count_[0, :]\n",
    "ham_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.63700000e+03,   5.30400000e+03,   0.00000000e+00, ...,\n",
       "         2.00000000e+00,   1.00000000e+00,   2.00000000e+00])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of times each token appears across all SPAM messages\n",
    "spam_token_count = nb.feature_count_[1, :]\n",
    "spam_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>2009.0</td>\n",
       "      <td>3637.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>390.0</td>\n",
       "      <td>5304.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000</th>\n",
       "      <td>376.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000</th>\n",
       "      <td>50.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000000</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ham    spam\n",
       "token                  \n",
       "00       2009.0  3637.0\n",
       "000       390.0  5304.0\n",
       "0000      376.0     0.0\n",
       "000000     50.0    62.0\n",
       "0000000     1.0     0.0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DataFrame of tokens with their separate ham and spam counts\n",
    "tokens = pd.DataFrame({'token':X_train_tokens, 'ham':ham_token_count, 'spam':spam_token_count}).set_index('token')\n",
    "tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bench</th>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bitmapsand</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gosses</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tome</th>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ham  spam\n",
       "token                 \n",
       "bench       14.0   7.0\n",
       "bitmapsand   1.0   0.0\n",
       "gosses       2.0   0.0\n",
       "tome         4.0   9.0\n",
       "1388         3.0   0.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine 5 random DataFrame rows\n",
    "tokens.sample(5, random_state=427)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8720.,  14510.])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes counts the number of observations in each class\n",
    "nb.class_count_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Before we can calculate the \"spamminess\" of each token, we need to avoid **dividing by zero** and account for the **class imbalance**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bench</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bitmapsand</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gosses</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tome</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ham  spam\n",
       "token                 \n",
       "bench       15.0   8.0\n",
       "bitmapsand   2.0   1.0\n",
       "gosses       3.0   1.0\n",
       "tome         5.0  10.0\n",
       "1388         4.0   1.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add 1 to ham and spam counts to avoid dividing by 0\n",
    "tokens['ham'] = tokens.ham + 1\n",
    "tokens['spam'] = tokens.spam + 1\n",
    "tokens.sample(5, random_state=427)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bench</th>\n",
       "      <td>0.001720</td>\n",
       "      <td>0.000551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bitmapsand</th>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gosses</th>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tome</th>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.000689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ham      spam\n",
       "token                         \n",
       "bench       0.001720  0.000551\n",
       "bitmapsand  0.000229  0.000069\n",
       "gosses      0.000344  0.000069\n",
       "tome        0.000573  0.000689\n",
       "1388        0.000459  0.000069"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the ham and spam counts into frequencies\n",
    "tokens['ham'] = tokens.ham / nb.class_count_[0]\n",
    "tokens['spam'] = tokens.spam / nb.class_count_[1]\n",
    "tokens.sample(5, random_state=427)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "      <th>spam_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bench</th>\n",
       "      <td>0.001720</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.320515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bitmapsand</th>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.300482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gosses</th>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.200322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tome</th>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>1.201930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.150241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ham      spam  spam_ratio\n",
       "token                                     \n",
       "bench       0.001720  0.000551    0.320515\n",
       "bitmapsand  0.000229  0.000069    0.300482\n",
       "gosses      0.000344  0.000069    0.200322\n",
       "tome        0.000573  0.000689    1.201930\n",
       "1388        0.000459  0.000069    0.150241"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the ratio of spam-to-ham for each token\n",
    "tokens['spam_ratio'] = tokens.spam / tokens.ham\n",
    "tokens.sample(5, random_state=427)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "      <th>spam_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>product_table</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.640662</td>\n",
       "      <td>5586.569263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15px</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.201447</td>\n",
       "      <td>1756.620262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0px</th>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.726465</td>\n",
       "      <td>1583.692626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proms</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.160510</td>\n",
       "      <td>1399.647140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>professionaladobe</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.160510</td>\n",
       "      <td>1399.647140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hereopt</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.125844</td>\n",
       "      <td>1097.361819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.122605</td>\n",
       "      <td>1069.116471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95more</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.120400</td>\n",
       "      <td>1049.885596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compacted_description</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.120400</td>\n",
       "      <td>1049.885596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewsretail</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.120400</td>\n",
       "      <td>1049.885596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00you</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.120400</td>\n",
       "      <td>1049.885596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoodia</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.109097</td>\n",
       "      <td>951.327360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs2</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.104893</td>\n",
       "      <td>914.668504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cantex</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.102481</td>\n",
       "      <td>893.634735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13px</th>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.201861</td>\n",
       "      <td>880.113025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>無料</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.098691</td>\n",
       "      <td>860.581668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weightzipping</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.081668</td>\n",
       "      <td>712.143349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bestsellers</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.081392</td>\n",
       "      <td>709.739490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sp_cont</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.080289</td>\n",
       "      <td>700.124052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5adobe</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.080289</td>\n",
       "      <td>700.124052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greylink</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.080289</td>\n",
       "      <td>700.124052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compacted_price</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.080289</td>\n",
       "      <td>700.124052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compacted_image</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.080289</td>\n",
       "      <td>700.124052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proadobe</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.080289</td>\n",
       "      <td>700.124052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00c</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.080289</td>\n",
       "      <td>700.124052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collectionadobe</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.080289</td>\n",
       "      <td>700.124052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rolex</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.058580</td>\n",
       "      <td>510.820124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discreet</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.058442</td>\n",
       "      <td>509.618194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bz</th>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.116678</td>\n",
       "      <td>508.716747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>herewant</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.055686</td>\n",
       "      <td>485.579600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fred</th>\n",
       "      <td>0.060894</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.001132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voltage</th>\n",
       "      <td>0.061124</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.001128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timedx</th>\n",
       "      <td>0.062729</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.001099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computing</th>\n",
       "      <td>0.063073</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.001093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analog</th>\n",
       "      <td>0.067890</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.001015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8babaaaaambg8afgd</th>\n",
       "      <td>0.068693</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.001003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weaeaaaacygdwawap</th>\n",
       "      <td>0.069037</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ir</th>\n",
       "      <td>0.069495</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>servo</th>\n",
       "      <td>0.070872</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sonar</th>\n",
       "      <td>0.071330</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starship</th>\n",
       "      <td>0.072706</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aqaqaaaajgypabya</th>\n",
       "      <td>0.075917</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgp</th>\n",
       "      <td>0.076720</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nil</th>\n",
       "      <td>0.231193</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sep</th>\n",
       "      <td>0.081307</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sensor</th>\n",
       "      <td>0.082339</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>routing</th>\n",
       "      <td>0.083830</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thu</th>\n",
       "      <td>0.087844</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>motors</th>\n",
       "      <td>0.095298</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linux</th>\n",
       "      <td>0.097592</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>libimlib</th>\n",
       "      <td>0.099197</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robot</th>\n",
       "      <td>0.113876</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>output</th>\n",
       "      <td>0.116628</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ribbon</th>\n",
       "      <td>0.121674</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>port</th>\n",
       "      <td>0.147248</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nodes</th>\n",
       "      <td>0.163532</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>node</th>\n",
       "      <td>0.166514</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>handy</th>\n",
       "      <td>0.167317</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cert</th>\n",
       "      <td>0.192775</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hb</th>\n",
       "      <td>0.193693</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161925 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            ham      spam   spam_ratio\n",
       "token                                                 \n",
       "product_table          0.000115  0.640662  5586.569263\n",
       "15px                   0.000115  0.201447  1756.620262\n",
       "0px                    0.000459  0.726465  1583.692626\n",
       "proms                  0.000115  0.160510  1399.647140\n",
       "professionaladobe      0.000115  0.160510  1399.647140\n",
       "hereopt                0.000115  0.125844  1097.361819\n",
       "fff                    0.000115  0.122605  1069.116471\n",
       "95more                 0.000115  0.120400  1049.885596\n",
       "compacted_description  0.000115  0.120400  1049.885596\n",
       "reviewsretail          0.000115  0.120400  1049.885596\n",
       "00you                  0.000115  0.120400  1049.885596\n",
       "hoodia                 0.000115  0.109097   951.327360\n",
       "cs2                    0.000115  0.104893   914.668504\n",
       "cantex                 0.000115  0.102481   893.634735\n",
       "13px                   0.000229  0.201861   880.113025\n",
       "無料                     0.000115  0.098691   860.581668\n",
       "weightzipping          0.000115  0.081668   712.143349\n",
       "bestsellers            0.000115  0.081392   709.739490\n",
       "sp_cont                0.000115  0.080289   700.124052\n",
       "5adobe                 0.000115  0.080289   700.124052\n",
       "greylink               0.000115  0.080289   700.124052\n",
       "compacted_price        0.000115  0.080289   700.124052\n",
       "compacted_image        0.000115  0.080289   700.124052\n",
       "proadobe               0.000115  0.080289   700.124052\n",
       "00c                    0.000115  0.080289   700.124052\n",
       "collectionadobe        0.000115  0.080289   700.124052\n",
       "rolex                  0.000115  0.058580   510.820124\n",
       "discreet               0.000115  0.058442   509.618194\n",
       "bz                     0.000229  0.116678   508.716747\n",
       "herewant               0.000115  0.055686   485.579600\n",
       "...                         ...       ...          ...\n",
       "fred                   0.060894  0.000069     0.001132\n",
       "voltage                0.061124  0.000069     0.001128\n",
       "timedx                 0.062729  0.000069     0.001099\n",
       "computing              0.063073  0.000069     0.001093\n",
       "analog                 0.067890  0.000069     0.001015\n",
       "8babaaaaambg8afgd      0.068693  0.000069     0.001003\n",
       "weaeaaaacygdwawap      0.069037  0.000069     0.000998\n",
       "ir                     0.069495  0.000069     0.000992\n",
       "servo                  0.070872  0.000069     0.000972\n",
       "sonar                  0.071330  0.000069     0.000966\n",
       "starship               0.072706  0.000069     0.000948\n",
       "aqaqaaaajgypabya       0.075917  0.000069     0.000908\n",
       "pgp                    0.076720  0.000069     0.000898\n",
       "nil                    0.231193  0.000207     0.000894\n",
       "sep                    0.081307  0.000069     0.000848\n",
       "sensor                 0.082339  0.000069     0.000837\n",
       "routing                0.083830  0.000069     0.000822\n",
       "thu                    0.087844  0.000069     0.000785\n",
       "motors                 0.095298  0.000069     0.000723\n",
       "linux                  0.097592  0.000069     0.000706\n",
       "libimlib               0.099197  0.000069     0.000695\n",
       "robot                  0.113876  0.000069     0.000605\n",
       "output                 0.116628  0.000069     0.000591\n",
       "ribbon                 0.121674  0.000069     0.000566\n",
       "port                   0.147248  0.000069     0.000468\n",
       "nodes                  0.163532  0.000069     0.000421\n",
       "node                   0.166514  0.000069     0.000414\n",
       "handy                  0.167317  0.000069     0.000412\n",
       "cert                   0.192775  0.000069     0.000358\n",
       "hb                     0.193693  0.000069     0.000356\n",
       "\n",
       "[161925 rows x 3 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the DataFrame sorted by spam_ratio\n",
    "# note: use sort() instead of sort_values() for pandas 0.16.2 and earlier\n",
    "tokens.sort_values('spam_ratio', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.449971806277802"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up the spam_ratio for a given token\n",
    "tokens.loc['adobe', 'spam_ratio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 9: Tuning the vectorizer (discussion)\n",
    "\n",
    "Thus far, we have been using the default parameters of [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show default parameters for CountVectorizer\n",
    "vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "However, the vectorizer is worth tuning, just like a model is worth tuning! Here are a few parameters that you might want to tune:\n",
    "\n",
    "- **stop_words:** string {'english'}, list, or None (default)\n",
    "    - If 'english', a built-in stop word list for English is used.\n",
    "    - If a list, that list is assumed to contain stop words, all of which will be removed from the resulting tokens.\n",
    "    - If None, no stop words will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# remove English stop words\n",
    "vect = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "- **ngram_range:** tuple (min_n, max_n), default=(1, 1)\n",
    "    - The lower and upper boundary of the range of n-values for different n-grams to be extracted.\n",
    "    - All values of n such that min_n <= n <= max_n will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# include 1-grams and 2-grams\n",
    "vect = CountVectorizer(ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "- **max_df:** float in range [0.0, 1.0] or int, default=1.0\n",
    "    - When building the vocabulary, ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words).\n",
    "    - If float, the parameter represents a proportion of documents.\n",
    "    - If integer, the parameter represents an absolute count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# ignore terms that appear in more than 50% of the documents\n",
    "vect = CountVectorizer(max_df=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "- **min_df:** float in range [0.0, 1.0] or int, default=1\n",
    "    - When building the vocabulary, ignore terms that have a document frequency strictly lower than the given threshold. (This value is also called \"cut-off\" in the literature.)\n",
    "    - If float, the parameter represents a proportion of documents.\n",
    "    - If integer, the parameter represents an absolute count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# only keep terms that appear in at least 2 documents\n",
    "vect = CountVectorizer(min_df=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "**Guidelines for tuning CountVectorizer:**\n",
    "\n",
    "- Use your knowledge of the **problem** and the **text**, and your understanding of the **tuning parameters**, to help you decide what parameters to tune and how to tune them.\n",
    "- **Experiment**, and let the data tell you the best approach!"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
