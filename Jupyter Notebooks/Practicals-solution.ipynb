{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Practicals: Spam Filtering with Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Agenda\n",
    "\n",
    "2. Representing text as numerical data\n",
    "3. Reading a text-based dataset into pandas\n",
    "4. Vectorizing our dataset\n",
    "5. Building and evaluating a model\n",
    "6. Comparing models\n",
    "7. Examining a model for further insight\n",
    "9. Tuning the vectorizer (challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 1: Representing text as numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# example text for model training\n",
    "simple_train = ['call you tonight', 'Call me a cab', 'please call me... PLEASE!']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    "\n",
    "> Text Analysis is a major application field for machine learning algorithms. However the raw data, a sequence of symbols cannot be fed directly to the algorithms themselves as most of them expect **numerical feature vectors with a fixed size** rather than the **raw text documents with variable length**.\n",
    "\n",
    "We will use [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) to \"convert text into a matrix of token counts\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# import and instantiate CountVectorizer (with the default parameters)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learn the 'vocabulary' of the training data (occurs in-place)\n",
    "vect.fit(simple_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cab', 'call', 'me', 'please', 'tonight', 'you']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the fitted vocabulary\n",
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x6 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 9 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform training data into a 'document-term matrix'\n",
    "simple_train_dtm = vect.transform(simple_train)\n",
    "simple_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 1, 1],\n",
       "       [1, 1, 1, 0, 0, 0],\n",
       "       [0, 1, 1, 2, 0, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert sparse matrix to a dense matrix\n",
    "simple_train_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    0     1   0       0        1    1\n",
       "1    1     1   1       0        0    0\n",
       "2    0     1   1       2        0    0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(simple_train_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    "\n",
    "> In this scheme, features and samples are defined as follows:\n",
    "\n",
    "> - Each individual token occurrence frequency (normalized or not) is treated as a **feature**.\n",
    "> - The vector of all the token frequencies for a given document is considered a multivariate **sample**.\n",
    "\n",
    "> A **corpus of documents** can thus be represented by a matrix with **one row per document** and **one column per token** (e.g. word) occurring in the corpus.\n",
    "\n",
    "> We call **vectorization** the general process of turning a collection of text documents into numerical feature vectors. This specific strategy (tokenization, counting and normalization) is called the **Bag of Words** or \"Bag of n-grams\" representation. Documents are described by word occurrences while completely ignoring the relative position information of the words in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the type of the document-term matrix\n",
    "type(simple_train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 2)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 3)\t2\n"
     ]
    }
   ],
   "source": [
    "# examine the sparse matrix contents\n",
    "print(simple_train_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    "\n",
    "> As most documents will typically use a very small subset of the words used in the corpus, the resulting matrix will have **many feature values that are zeros** (typically more than 99% of them).\n",
    "\n",
    "> For instance, a collection of 10,000 short text documents (such as emails) will use a vocabulary with a size in the order of 100,000 unique words in total while each document will use 100 to 1000 unique words individually.\n",
    "\n",
    "> In order to be able to **store such a matrix in memory** but also to **speed up operations**, implementations will typically use a **sparse representation** such as the implementations available in the `scipy.sparse` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# example text for model testing\n",
    "simple_test = [\"please don't call me\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "In order to **make a prediction**, the new observation must have the **same features as the training observations**, both in number and meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data into a document-term matrix (using existing vocabulary)\n",
    "simple_test_dtm = vect.transform(simple_test)\n",
    "simple_test_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    0     1   1       1        0    0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(simple_test_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "**Summary:**\n",
    "\n",
    "- `vect.fit(train)` **learns the vocabulary** of the training data\n",
    "- `vect.transform(train)` uses the **fitted vocabulary** to build a document-term matrix from the training data\n",
    "- `vect.transform(test)` uses the **fitted vocabulary** to build a document-term matrix from the testing data (and **ignores tokens** it hasn't seen before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 3: Reading a text-based dataset into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# read file into pandas using a relative path\n",
    "path = 'data/spam_ham.csv'\n",
    "spam_ham = pd.read_csv(path, header=0, names=['label', 'location','message'])\n",
    "spam_ham.drop('location', axis=1, inplace=True)\n",
    "spam_ham.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30974, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the shape\n",
    "spam_ham.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>LUXURY WATCHES - BUY YOUR OWN ROLEX FOR ONLY $...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Academic Qualifications available from prestig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Greetings all. This is to verify your subscrip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>try chauncey may conferred the luscious not co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>It's quiet. Too quiet. Well, how about a straw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>It's working here. I have departed almost tota...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spam</td>\n",
       "      <td>The OIL sector is going crazy. This is our wee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spam</td>\n",
       "      <td>Little magic. Perfect weekends.http://othxu.rz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ham</td>\n",
       "      <td>Greetings all. This is a mass acknowledgement ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hi, L C P A X V V e I r m a A I v A o b n L A ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0  spam  LUXURY WATCHES - BUY YOUR OWN ROLEX FOR ONLY $...\n",
       "1  spam  Academic Qualifications available from prestig...\n",
       "2   ham  Greetings all. This is to verify your subscrip...\n",
       "3  spam  try chauncey may conferred the luscious not co...\n",
       "4   ham  It's quiet. Too quiet. Well, how about a straw...\n",
       "5   ham  It's working here. I have departed almost tota...\n",
       "6  spam  The OIL sector is going crazy. This is our wee...\n",
       "7  spam  Little magic. Perfect weekends.http://othxu.rz...\n",
       "8   ham  Greetings all. This is a mass acknowledgement ...\n",
       "9  spam  Hi, L C P A X V V e I r m a A I v A o b n L A ..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the first 10 rows\n",
    "spam_ham.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam    19280\n",
       "ham     11694\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the class distribution\n",
    "spam_ham.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# convert label to a numerical variable\n",
    "spam_ham['label_num'] = spam_ham.label.map({'ham':0, 'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>LUXURY WATCHES - BUY YOUR OWN ROLEX FOR ONLY $...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Academic Qualifications available from prestig...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Greetings all. This is to verify your subscrip...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>try chauncey may conferred the luscious not co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>It's quiet. Too quiet. Well, how about a straw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>It's working here. I have departed almost tota...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spam</td>\n",
       "      <td>The OIL sector is going crazy. This is our wee...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spam</td>\n",
       "      <td>Little magic. Perfect weekends.http://othxu.rz...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ham</td>\n",
       "      <td>Greetings all. This is a mass acknowledgement ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hi, L C P A X V V e I r m a A I v A o b n L A ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  label_num\n",
       "0  spam  LUXURY WATCHES - BUY YOUR OWN ROLEX FOR ONLY $...          1\n",
       "1  spam  Academic Qualifications available from prestig...          1\n",
       "2   ham  Greetings all. This is to verify your subscrip...          0\n",
       "3  spam  try chauncey may conferred the luscious not co...          1\n",
       "4   ham  It's quiet. Too quiet. Well, how about a straw...          0\n",
       "5   ham  It's working here. I have departed almost tota...          0\n",
       "6  spam  The OIL sector is going crazy. This is our wee...          1\n",
       "7  spam  Little magic. Perfect weekends.http://othxu.rz...          1\n",
       "8   ham  Greetings all. This is a mass acknowledgement ...          0\n",
       "9  spam  Hi, L C P A X V V e I r m a A I v A o b n L A ...          1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that the conversion worked\n",
    "spam_ham.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30974,)\n",
      "(30974,)\n"
     ]
    }
   ],
   "source": [
    "# how to define X and y (from the SMS data) for use with COUNTVECTORIZER\n",
    "X = spam_ham.message\n",
    "y = spam_ham.label_num\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23230,)\n",
      "(7744,)\n",
      "(23230,)\n",
      "(7744,)\n"
     ]
    }
   ],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=427)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 4: Vectorizing our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# instantiate the vectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learn training data vocabulary, then use it to create a document-term matrix\n",
    "vect.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '0000',\n",
       " '000000',\n",
       " '0000000',\n",
       " '00000000',\n",
       " '000000000',\n",
       " '00000000000000',\n",
       " '000000000000000000000000000000049999999999999e9',\n",
       " '0000000000000000000000000000000500000000000000e9',\n",
       " '0000000000000016666l',\n",
       " '0000000000000017d',\n",
       " '00000000000000e',\n",
       " '000000000000received',\n",
       " '000000000001received',\n",
       " '0000000001d0',\n",
       " '0000000001l0',\n",
       " '0000000010000000004l0',\n",
       " '0000000016',\n",
       " '000000001d0',\n",
       " '00000000message',\n",
       " '00000000x',\n",
       " '00000001',\n",
       " '00000001content',\n",
       " '00000001irdecode',\n",
       " '00000004',\n",
       " '00000010',\n",
       " '00000010pwm',\n",
       " '00000011',\n",
       " '00000049',\n",
       " '0000005',\n",
       " '0000006hz',\n",
       " '000000eb',\n",
       " '000001',\n",
       " '00000100',\n",
       " '00000100shaftencoder',\n",
       " '000001bdaaa0',\n",
       " '000001bdb744',\n",
       " '000001bdcaf3',\n",
       " '000001c642d0',\n",
       " '000001c64310',\n",
       " '000001c64585',\n",
       " '000001c64615',\n",
       " '000001c64641',\n",
       " '000001c6465f',\n",
       " '000001c6468e',\n",
       " '0000020',\n",
       " '0000040',\n",
       " '0000040b',\n",
       " '0000040c',\n",
       " '000005',\n",
       " '0000060',\n",
       " '00000dd0',\n",
       " '00001',\n",
       " '000010',\n",
       " '0000100',\n",
       " '00001000',\n",
       " '00001004',\n",
       " '00001008',\n",
       " '0000100c',\n",
       " '00001010',\n",
       " '00001014',\n",
       " '00001018',\n",
       " '0000101c',\n",
       " '00001023',\n",
       " '00001026',\n",
       " '00001028',\n",
       " '0000102c',\n",
       " '00001030',\n",
       " '00001034',\n",
       " '00001038',\n",
       " '0000103e',\n",
       " '00001040',\n",
       " '00001044',\n",
       " '00001048',\n",
       " '0000104c',\n",
       " '00001050',\n",
       " '00001054',\n",
       " '0000105a',\n",
       " '0000105ci',\n",
       " '0000120',\n",
       " '0000140',\n",
       " '0000160',\n",
       " '00001808',\n",
       " '0000180cmain',\n",
       " '0000200',\n",
       " '0000220',\n",
       " '0000240',\n",
       " '0000260',\n",
       " '0000300',\n",
       " '00003001722',\n",
       " '000031',\n",
       " '0000320',\n",
       " '0000340',\n",
       " '0000360',\n",
       " '00004',\n",
       " '0000400',\n",
       " '0000420',\n",
       " '0000440',\n",
       " '000046',\n",
       " '0000460',\n",
       " '0000500',\n",
       " '0000504',\n",
       " '000061',\n",
       " '000066',\n",
       " '000076',\n",
       " '000092',\n",
       " '00009800',\n",
       " '00009804',\n",
       " '0000bi',\n",
       " '0000bytes',\n",
       " '0000comment',\n",
       " '0000content',\n",
       " '0000d5',\n",
       " '0000date',\n",
       " '0000david',\n",
       " '0000delivered',\n",
       " '0000ff',\n",
       " '0000from',\n",
       " '0000importance',\n",
       " '0000in',\n",
       " '0000institute',\n",
       " '0000instituteof0000',\n",
       " '0000message',\n",
       " '0000mime',\n",
       " '0000nline',\n",
       " '0000nology',\n",
       " '0000nology404',\n",
       " '0000of',\n",
       " '0000organization',\n",
       " '0000our',\n",
       " '0000received',\n",
       " '0000reply',\n",
       " '0000scott',\n",
       " '0000to',\n",
       " '0000x',\n",
       " '0001',\n",
       " '00010000',\n",
       " '000101376290',\n",
       " '000101bdcbb7',\n",
       " '00010246',\n",
       " '00010246ebx',\n",
       " '000107',\n",
       " '00011',\n",
       " '00014',\n",
       " '0001_mayprod',\n",
       " '0001jn',\n",
       " '0001pt',\n",
       " '0001we',\n",
       " '0001x',\n",
       " '0002',\n",
       " '000201bdaabb',\n",
       " '000201bdc8cb',\n",
       " '000201bdcbb8',\n",
       " '000201c265a3',\n",
       " '00024355',\n",
       " '000255000',\n",
       " '0002phone',\n",
       " '0003',\n",
       " '000301c634d3',\n",
       " '000301c6430e',\n",
       " '00033577',\n",
       " '0003qj',\n",
       " '0004',\n",
       " '00048z',\n",
       " '0004ek',\n",
       " '0004ti',\n",
       " '0005',\n",
       " '000501bdca45',\n",
       " '000501c62cfa',\n",
       " '000548',\n",
       " '0006',\n",
       " '0006ms',\n",
       " '0006pn',\n",
       " '0006z8',\n",
       " '0007',\n",
       " '00077u',\n",
       " '0007ka',\n",
       " '0008',\n",
       " '000801c59181',\n",
       " '0009',\n",
       " '000901c0e23e',\n",
       " '0009lcdrout',\n",
       " '000a',\n",
       " '000a01bdea63',\n",
       " '000antiprotons',\n",
       " '000audre',\n",
       " '000b01c66cb8',\n",
       " '000bachelor',\n",
       " '000barrels',\n",
       " '000br',\n",
       " '000c',\n",
       " '000c01bdcdc7',\n",
       " '000c01c6714b',\n",
       " '000company',\n",
       " '000dear',\n",
       " '000doctorate',\n",
       " '000e',\n",
       " '000e137038fe07f0ea1e00000e1370ad14f0a238060170380382783800fc7f18157f941b',\n",
       " '000equals',\n",
       " '000eur',\n",
       " '000f01bee9ca',\n",
       " '000f01c0fa97',\n",
       " '000hours',\n",
       " '000i',\n",
       " '000in',\n",
       " '000industry',\n",
       " '000k',\n",
       " '000live',\n",
       " '000m',\n",
       " '000master',\n",
       " '000mk',\n",
       " '000no',\n",
       " '000over',\n",
       " '000rpm',\n",
       " '000some',\n",
       " '000stipend',\n",
       " '000summary',\n",
       " '000t',\n",
       " '000this',\n",
       " '000uponcompletion',\n",
       " '000visitors',\n",
       " '000yes',\n",
       " '000you',\n",
       " '000контактные',\n",
       " '000アブノーマル1時間',\n",
       " '000元',\n",
       " '000元以內',\n",
       " '000円',\n",
       " '000円のみが必要となりますが',\n",
       " '000円不要',\n",
       " '000性感ノーマル',\n",
       " '001',\n",
       " '0010',\n",
       " '00100000',\n",
       " '00100001',\n",
       " '001001bee9ca',\n",
       " '00101380381e0700ea1fff5b13f8ea17e00010c7fca6ea11f8ea120cea1c07381803801210380001c0a214e0a4127012f0a200e013c01280ea4003148038200700ea1006ea0c1cea03f013227ea018',\n",
       " '0011',\n",
       " '001111111',\n",
       " '0012',\n",
       " '001201bee9d7',\n",
       " '001201beedd8',\n",
       " '00126',\n",
       " '0013',\n",
       " '0014',\n",
       " '001401bf04c9',\n",
       " '001501bde71a',\n",
       " '001532edt',\n",
       " '001601bde7b0',\n",
       " '001701bde82b',\n",
       " '0018',\n",
       " '001801bde88a',\n",
       " '001888',\n",
       " '0019',\n",
       " '00191',\n",
       " '001a',\n",
       " '001aa',\n",
       " '001d',\n",
       " '001e133000231370ea438014e01283ea8700a2380701c0120ea3381c0380a4eb0700a35bea0c3eea03ceea000ea25b1260eaf0381330485aea80c0ea4380003ec7fc141f7b9418',\n",
       " '001e1360002313e0ea4380eb81c01283ea8701a238070380120ea3381c0700a31408eb0e101218121ceb1e20ea0c263807c3c015157b941a',\n",
       " '001eb1ec',\n",
       " '001eboard',\n",
       " '001eeb60e00023ebe0f0384380e1eb81c000831470d887011330a23907038020120ea3391c070040a31580a2ec0100130f380c0b02380613843803e0f81c157b9420',\n",
       " '001f01c0faab',\n",
       " '001f01c275ca',\n",
       " '001fb512f8391e03c03800181418123038200780a200401410a2eb0f001280a200001400131ea45ba45ba45ba4485aa41203b5fc1d2277a123',\n",
       " '001fboard',\n",
       " '001fd',\n",
       " '001kp',\n",
       " '001mk',\n",
       " '002',\n",
       " '0020',\n",
       " '00203228888',\n",
       " '0020afec18ca',\n",
       " '0020j',\n",
       " '0021',\n",
       " '00212',\n",
       " '0022',\n",
       " '002249',\n",
       " '002289481249mail',\n",
       " '0022uf',\n",
       " '0023',\n",
       " '002321',\n",
       " '00233',\n",
       " '0024',\n",
       " '0025',\n",
       " '0025fax',\n",
       " '0026',\n",
       " '002601c66a38',\n",
       " '0027',\n",
       " '002712est',\n",
       " '0028',\n",
       " '002801c13bab',\n",
       " '0028ii',\n",
       " '0029',\n",
       " '002930_voxinfo',\n",
       " '0029817706609725333l434294481',\n",
       " '002983',\n",
       " '0029porta',\n",
       " '002_dragon004200943940content',\n",
       " '002_dragon008535651103',\n",
       " '002_dragon013699393919',\n",
       " '002_dragon019357534987content',\n",
       " '002_dragon020181421106',\n",
       " '002_dragon032685489904content',\n",
       " '002_dragon034150072259',\n",
       " '002_dragon034633567807content',\n",
       " '002_dragon039925383399content',\n",
       " '002_dragon040476364422',\n",
       " '002_dragon048889247829content',\n",
       " '002_dragon056675156800',\n",
       " '002_dragon058285243905content',\n",
       " '002_dragon060280103893content',\n",
       " '002_dragon073148149514',\n",
       " '002_dragon074457059520',\n",
       " '002_dragon077329414837',\n",
       " '002_dragon080566096389content',\n",
       " '002_dragon092734619076content',\n",
       " '002_dragon100455099132content',\n",
       " '002_dragon108076263577content',\n",
       " '002_dragon108468622097content',\n",
       " '002_dragon120569444328',\n",
       " '002_dragon122521392039content',\n",
       " '002_dragon128631707502content',\n",
       " '002_dragon133773915096content',\n",
       " '002_dragon136224228356content',\n",
       " '002_dragon138839954923',\n",
       " '002_dragon140844353194',\n",
       " '002_dragon142360745850content',\n",
       " '002_dragon143330654218',\n",
       " '002_dragon149449844292',\n",
       " '002_dragon161509917710',\n",
       " '002_dragon162756092795content',\n",
       " '002_dragon168204929497content',\n",
       " '002_dragon169002695074',\n",
       " '002_dragon169085030403content',\n",
       " '002_dragon176086318908',\n",
       " '002_dragon177944757813content',\n",
       " '002_dragon179326334746',\n",
       " '002_dragon183888777798content',\n",
       " '002_dragon183941553104content',\n",
       " '002_dragon185781585974',\n",
       " '002_dragon186514966961_',\n",
       " '002_dragon188257448684content',\n",
       " '002_dragon188333289331content',\n",
       " '002_dragon189316002559content',\n",
       " '002_dragon193530954717content',\n",
       " '002_dragon196072547742',\n",
       " '002_dragon198189501342content',\n",
       " '002_dragon203013389770content',\n",
       " '002_dragon204052897310',\n",
       " '002_dragon205793002835content',\n",
       " '002_dragon206018273441content',\n",
       " '002_dragon207785784570content',\n",
       " '002_dragon210159025107content',\n",
       " '002_dragon211481662238',\n",
       " '002_dragon212983034666content',\n",
       " '002_dragon213924637584content',\n",
       " '002_dragon214166912429',\n",
       " '002_dragon214895540320',\n",
       " '002_dragon215886918037',\n",
       " '002_dragon216410465126content',\n",
       " '002_dragon231888896784content',\n",
       " '002_dragon233134712957content',\n",
       " '002_dragon234879898522content',\n",
       " '002_dragon235764159952content',\n",
       " '002_dragon237516939735',\n",
       " '002_dragon239516577637content',\n",
       " '002_dragon240032945636content',\n",
       " '002_dragon248564804421content',\n",
       " '002_dragon249354945590content',\n",
       " '002_dragon249807569787content',\n",
       " '002_dragon254481303756',\n",
       " '002_dragon256918362398',\n",
       " '002_dragon262221859113',\n",
       " '002_dragon264396653478',\n",
       " '002_dragon264441716722content',\n",
       " '002_dragon265325440711content',\n",
       " '002_dragon266209308694content',\n",
       " '002_dragon269013230617content',\n",
       " '002_dragon270367826058content',\n",
       " '002_dragon273382864054content',\n",
       " '002_dragon273895548293',\n",
       " '002_dragon281660342386content',\n",
       " '002_dragon285173245356content',\n",
       " '002_dragon289924567963content',\n",
       " '002_dragon291265061908content',\n",
       " '002_dragon292505557095content',\n",
       " '002_dragon293119990835content',\n",
       " '002_dragon295843020376content',\n",
       " '002_dragon302510766348',\n",
       " '002_dragon302921738635',\n",
       " '002_dragon310127751282content',\n",
       " '002_dragon310651914794content',\n",
       " '002_dragon313149702908',\n",
       " '002_dragon317695925892content',\n",
       " '002_dragon318665289543content',\n",
       " '002_dragon319948883600',\n",
       " '002_dragon320946592690content',\n",
       " '002_dragon322915006407',\n",
       " '002_dragon324589698709content',\n",
       " '002_dragon327437312378content',\n",
       " '002_dragon327643673166content',\n",
       " '002_dragon330573254373content',\n",
       " '002_dragon333436883450content',\n",
       " '002_dragon336214030309content',\n",
       " '002_dragon340834821974',\n",
       " '002_dragon341612040241',\n",
       " '002_dragon343333554216',\n",
       " '002_dragon345724565924content',\n",
       " '002_dragon346394276285content',\n",
       " '002_dragon348016147037content',\n",
       " '002_dragon356616615600content',\n",
       " '002_dragon359805902139content',\n",
       " '002_dragon361767389765',\n",
       " '002_dragon366284922033',\n",
       " '002_dragon370830372714',\n",
       " '002_dragon377070002978content',\n",
       " '002_dragon377441852287',\n",
       " '002_dragon384660614980content',\n",
       " '002_dragon389780210192content',\n",
       " '002_dragon390632298472content',\n",
       " '002_dragon391848222368content',\n",
       " '002_dragon399477789492content',\n",
       " '002_dragon402079065150',\n",
       " '002_dragon402740244099content',\n",
       " '002_dragon409823729458content',\n",
       " '002_dragon410509063251content',\n",
       " '002_dragon411110209560content',\n",
       " '002_dragon413436947052content',\n",
       " '002_dragon415805250710content',\n",
       " '002_dragon416123410162content',\n",
       " '002_dragon425323668785content',\n",
       " '002_dragon431429810021content',\n",
       " '002_dragon431676018905content',\n",
       " '002_dragon432852498332content',\n",
       " '002_dragon437917652885content',\n",
       " '002_dragon440034119332',\n",
       " '002_dragon441674338630',\n",
       " '002_dragon442592498835',\n",
       " '002_dragon443472164152content',\n",
       " '002_dragon443689150123content',\n",
       " '002_dragon444004361912content',\n",
       " '002_dragon448288168555content',\n",
       " '002_dragon451319953791',\n",
       " '002_dragon451657700235content',\n",
       " '002_dragon456176210945content',\n",
       " '002_dragon468266803279content',\n",
       " '002_dragon470466639645',\n",
       " '002_dragon473323566965',\n",
       " '002_dragon476540816282content',\n",
       " '002_dragon477399743496content',\n",
       " '002_dragon479331544790content',\n",
       " '002_dragon483579780476content',\n",
       " '002_dragon484358097899content',\n",
       " '002_dragon488902243432',\n",
       " '002_dragon491393046235',\n",
       " '002_dragon495877656850content',\n",
       " '002_dragon504217449345',\n",
       " '002_dragon505110412875',\n",
       " '002_dragon505932322972',\n",
       " '002_dragon506805364816content',\n",
       " '002_dragon508712711421content',\n",
       " '002_dragon512122577234',\n",
       " '002_dragon513692340014content',\n",
       " '002_dragon514676478309content',\n",
       " '002_dragon515128794190',\n",
       " '002_dragon516011979524content',\n",
       " '002_dragon516666948361content',\n",
       " '002_dragon518255923908content',\n",
       " '002_dragon519557785805',\n",
       " '002_dragon520683972230content',\n",
       " '002_dragon522040799568',\n",
       " '002_dragon527791339896content',\n",
       " '002_dragon530821623860content',\n",
       " '002_dragon533304058117_',\n",
       " '002_dragon533835082890content',\n",
       " '002_dragon535670459181content',\n",
       " '002_dragon536989065088content',\n",
       " '002_dragon538638107395content',\n",
       " '002_dragon540629808243content',\n",
       " '002_dragon542105054566content',\n",
       " '002_dragon542522505882content',\n",
       " '002_dragon544018013072content',\n",
       " '002_dragon546536074428content',\n",
       " '002_dragon547081415263content',\n",
       " '002_dragon547831489158',\n",
       " '002_dragon554816776882content',\n",
       " '002_dragon557516700063content',\n",
       " '002_dragon558995758314',\n",
       " '002_dragon560194215614content',\n",
       " '002_dragon561824435930content',\n",
       " '002_dragon563227845761',\n",
       " '002_dragon564322207242content',\n",
       " '002_dragon571434638457',\n",
       " '002_dragon574371893608content',\n",
       " '002_dragon575169100404_',\n",
       " '002_dragon575585758776content',\n",
       " '002_dragon577596397905content',\n",
       " '002_dragon583411697069content',\n",
       " '002_dragon584915480615',\n",
       " '002_dragon585001720044content',\n",
       " '002_dragon585387820253',\n",
       " '002_dragon586232798130content',\n",
       " '002_dragon591660557037content',\n",
       " '002_dragon596828381337content',\n",
       " '002_dragon597439856990',\n",
       " '002_dragon599296306728',\n",
       " '002_dragon610136592431content',\n",
       " '002_dragon610953810273content',\n",
       " '002_dragon619468299972content',\n",
       " '002_dragon623245546434',\n",
       " '002_dragon623495405341content',\n",
       " '002_dragon625493329806content',\n",
       " '002_dragon634337155732content',\n",
       " '002_dragon636962270343content',\n",
       " '002_dragon643501113307',\n",
       " '002_dragon645239832728',\n",
       " '002_dragon645469919759content',\n",
       " '002_dragon647819242747content',\n",
       " '002_dragon648837860654content',\n",
       " '002_dragon660060898871content',\n",
       " '002_dragon660123564464content',\n",
       " '002_dragon664173122785content',\n",
       " '002_dragon669679313152content',\n",
       " '002_dragon671339860625content',\n",
       " '002_dragon671413180375',\n",
       " '002_dragon682176656828',\n",
       " '002_dragon682242077477',\n",
       " '002_dragon683701003467',\n",
       " '002_dragon683848968845',\n",
       " '002_dragon684485696525content',\n",
       " '002_dragon685743176115content',\n",
       " '002_dragon700393232030content',\n",
       " '002_dragon702086349026',\n",
       " '002_dragon706880655832content',\n",
       " '002_dragon710680206378',\n",
       " '002_dragon714483479317content',\n",
       " '002_dragon715506809858content',\n",
       " '002_dragon721447944431content',\n",
       " '002_dragon721496209399content',\n",
       " '002_dragon735922421923content',\n",
       " '002_dragon744366455165',\n",
       " '002_dragon745440808393content',\n",
       " '002_dragon745846869871content',\n",
       " '002_dragon749046174059',\n",
       " '002_dragon749135313276content',\n",
       " '002_dragon749616001928content',\n",
       " '002_dragon749775980445',\n",
       " '002_dragon752042517009content',\n",
       " '002_dragon752940174982content',\n",
       " '002_dragon756883035274content',\n",
       " '002_dragon758472607762',\n",
       " '002_dragon760169235045content',\n",
       " '002_dragon762646400558content',\n",
       " '002_dragon763409779758',\n",
       " '002_dragon773027103006',\n",
       " '002_dragon777504927530',\n",
       " '002_dragon779053823085content',\n",
       " '002_dragon779723947235content',\n",
       " '002_dragon785824725207',\n",
       " '002_dragon785883807422content',\n",
       " '002_dragon787036265046',\n",
       " '002_dragon788617422663',\n",
       " '002_dragon789549662168content',\n",
       " '002_dragon790560539053',\n",
       " '002_dragon790568223600',\n",
       " '002_dragon796954387895content',\n",
       " '002_dragon799105077372',\n",
       " '002_dragon803951708982content',\n",
       " '002_dragon805058253897content',\n",
       " '002_dragon806793363072',\n",
       " '002_dragon809654126877_',\n",
       " '002_dragon809864011866content',\n",
       " '002_dragon813633483461content',\n",
       " '002_dragon813978104655',\n",
       " '002_dragon820046601046content',\n",
       " '002_dragon821031089314content',\n",
       " '002_dragon833788956448_',\n",
       " '002_dragon835344230368content',\n",
       " '002_dragon835873675296content',\n",
       " '002_dragon836071345290',\n",
       " '002_dragon837387913413content',\n",
       " '002_dragon838552296986',\n",
       " '002_dragon844804994340content',\n",
       " '002_dragon852494520224',\n",
       " '002_dragon853396716332content',\n",
       " '002_dragon859035731542',\n",
       " '002_dragon866142856789',\n",
       " '002_dragon871663965498',\n",
       " '002_dragon872235195865content',\n",
       " '002_dragon875584409480content',\n",
       " '002_dragon882261761834',\n",
       " '002_dragon882895304044content',\n",
       " '002_dragon887388321534content',\n",
       " '002_dragon890168734255',\n",
       " '002_dragon890932882408content',\n",
       " '002_dragon898049280100content',\n",
       " '002_dragon908062144026content',\n",
       " '002_dragon912634163458content',\n",
       " '002_dragon917066359101',\n",
       " '002_dragon943687789736',\n",
       " '002_dragon953322195972content',\n",
       " '002_dragon955500430856content',\n",
       " '002_dragon956476021852content',\n",
       " '002_dragon959715935339content',\n",
       " '002_dragon966803059116content',\n",
       " '002_dragon975760983408content',\n",
       " '002_dragon975935048487content',\n",
       " '002_dragon980145547667content',\n",
       " '002_dragon981554492198content',\n",
       " '002_dragon984547041819',\n",
       " '002_dragon986057447477content',\n",
       " '002_dragon993740048225content',\n",
       " '002_dragon998760730906',\n",
       " '002_dragon998895130427content',\n",
       " '002a01c2724f',\n",
       " '002br',\n",
       " '002d01c26659',\n",
       " '002d01c66d57',\n",
       " '002d16e0',\n",
       " '002d16e0content',\n",
       " '002data',\n",
       " '002e62',\n",
       " '002f40f4',\n",
       " '002hn',\n",
       " '002mk',\n",
       " '002time',\n",
       " '003',\n",
       " '0030',\n",
       " '003001bee908',\n",
       " '00301320383e01e0383fffc0148014005b13f8ea33c00030c7fca4ea31fcea37ff383e0fc0383807e0ea3003000013f0a214f8a21238127c12fea200fc13f0a2387007e0003013c0383c1f80380fff00ea03f815207d9f1c',\n",
       " '0031',\n",
       " '00316',\n",
       " '0031630926532',\n",
       " '0031847131601',\n",
       " '003201c67c38',\n",
       " '0033',\n",
       " '003301beebdc',\n",
       " '003366',\n",
       " '003399',\n",
       " '0034',\n",
       " '0034pulse_default',\n",
       " '0034tcnt',\n",
       " '0035',\n",
       " '003501beebdf',\n",
       " '0038',\n",
       " '0039',\n",
       " '003901beebdf',\n",
       " '003901c67c7a',\n",
       " '003_dragon056507828553_',\n",
       " '003_dragon340468286956_',\n",
       " '003_dragon346143145919_',\n",
       " '003_dragon426402787230_',\n",
       " '003_dragon744672031743_',\n",
       " '003br',\n",
       " '003fax',\n",
       " '003nl',\n",
       " '003pt',\n",
       " '004',\n",
       " '0040',\n",
       " '0040095e21234',\n",
       " '004093',\n",
       " '0040b0b1',\n",
       " '0040b0b10069f628',\n",
       " '0040b530',\n",
       " '0041',\n",
       " '004101c67c3c',\n",
       " '0042',\n",
       " '004201beebf9',\n",
       " '0043',\n",
       " '0043c77a',\n",
       " '0043fec0',\n",
       " '0044',\n",
       " '004499',\n",
       " '0044eb9c',\n",
       " '0044f6dc',\n",
       " '0045subroutine_servo_a5_init',\n",
       " '00468078',\n",
       " '0046937f',\n",
       " '00469d74',\n",
       " '00469d76',\n",
       " '0048',\n",
       " '0049',\n",
       " '0049servo_a5_pulse',\n",
       " '004c',\n",
       " '004nl',\n",
       " '005',\n",
       " '005004',\n",
       " '0050servo_a5_int',\n",
       " '005135',\n",
       " '0052servo_bit',\n",
       " '0053',\n",
       " '005301beedb7',\n",
       " '0054',\n",
       " '0058',\n",
       " '0059',\n",
       " '0059variable_servo_a5_pulse',\n",
       " '005a',\n",
       " '005amicrosoft',\n",
       " '005aupdate',\n",
       " '005c',\n",
       " '005d01bf6f13',\n",
       " '005hn',\n",
       " '005la',\n",
       " '005mk',\n",
       " '006',\n",
       " '0060',\n",
       " '00632d93',\n",
       " '0063825485257156_',\n",
       " '0063825485257156_content',\n",
       " '0063825785257156_',\n",
       " '0063825785257156_content',\n",
       " '00638260',\n",
       " '0063servo_enable',\n",
       " '0064',\n",
       " '0064setup_gap',\n",
       " '0065',\n",
       " '00664e75',\n",
       " '00667',\n",
       " '00667280',\n",
       " '0066993785257156_',\n",
       " '0066993785257156_content',\n",
       " '0066993a85257156_',\n",
       " '0066993a85257156_content',\n",
       " '00669945',\n",
       " '006765d8',\n",
       " '0067tctl1',\n",
       " '0068',\n",
       " '0068a474',\n",
       " '0068a574',\n",
       " '0068da84',\n",
       " '0068uf',\n",
       " '0068uff',\n",
       " '0069',\n",
       " '0069d154',\n",
       " '0069f5b8',\n",
       " '0069f5e0',\n",
       " '0069f5e0ecx',\n",
       " '0069f628',\n",
       " '0069fa36',\n",
       " '0069fcf8',\n",
       " '006a',\n",
       " '006b57d8',\n",
       " '006bb7f8',\n",
       " '006c2ce4',\n",
       " '006c67cc',\n",
       " '006e',\n",
       " '006hn',\n",
       " '006hz',\n",
       " '006karnatakaindiaph',\n",
       " '006la',\n",
       " '006mk',\n",
       " '006nl',\n",
       " '006ov',\n",
       " '006performing',\n",
       " '007',\n",
       " '0070',\n",
       " '007083ac',\n",
       " '0071',\n",
       " '00717',\n",
       " '0072',\n",
       " '0072for',\n",
       " '0073',\n",
       " '0074',\n",
       " '0075',\n",
       " '0076194298',\n",
       " '00762',\n",
       " '0077',\n",
       " '0077author',\n",
       " '0078',\n",
       " '0078title',\n",
       " '00794d20',\n",
       " '00795ce0',\n",
       " '00798ab0',\n",
       " '007a4e40',\n",
       " '007b0100',\n",
       " '007b5860',\n",
       " '007br',\n",
       " '007cb350',\n",
       " '007fb512f839780780780060141800401408a300c0140c00801404a400001400b3a3497e3801fffe1e227ea123',\n",
       " '007fb61280a2397e03f80f00781407007014030060140100e015c0a200c01400a400001500b3a248b512f0a222227ea127',\n",
       " '007fb8fca39039c00ff801d87e00ec003f007c82007882a200708200f01780a3481603a5c792c7fcb3aa017fb6fca331307daf38',\n",
       " '007fd',\n",
       " '007parkerbros',\n",
       " '007you',\n",
       " '008',\n",
       " '0080',\n",
       " '00800',\n",
       " '008000',\n",
       " '0081',\n",
       " '0082',\n",
       " '0082toc3',\n",
       " '0083903358',\n",
       " '0084',\n",
       " '008482',\n",
       " '0085',\n",
       " '0085weekly',\n",
       " '0087',\n",
       " '008723514',\n",
       " '0087411652337',\n",
       " '0088cforc',\n",
       " '0088office',\n",
       " '0089',\n",
       " '0089tmsk1',\n",
       " '008br',\n",
       " '008ov',\n",
       " '008scan1',\n",
       " '008scan1testa',\n",
       " '009',\n",
       " '0090',\n",
       " '00901a',\n",
       " '0091',\n",
       " '0092',\n",
       " '0093',\n",
       " '0093according',\n",
       " '0093bac',\n",
       " '0093calls',\n",
       " '0093contact',\n",
       " '0093no',\n",
       " '0093subroutine_initialize_module',\n",
       " '0095setup_pulse',\n",
       " '0096',\n",
       " '0097612',\n",
       " '0097616095',\n",
       " '0098',\n",
       " '0098d3',\n",
       " '0099',\n",
       " '009901c29c95',\n",
       " '0099ff',\n",
       " '009a01c29c9a',\n",
       " '009baba3',\n",
       " '009br',\n",
       " '009c01bee96b',\n",
       " '009c0380',\n",
       " '009mk',\n",
       " '00a301bee7d1',\n",
       " '00aa00342820',\n",
       " '00aa01c59196',\n",
       " '00am',\n",
       " '00analog',\n",
       " '00assistant',\n",
       " '00b14878',\n",
       " '00c',\n",
       " '00c04fd7081f',\n",
       " '00c04fd97575',\n",
       " '00can',\n",
       " '00cf01bee7d2',\n",
       " '00customers',\n",
       " '00dc',\n",
       " '00ddvtnaxl7vqmz',\n",
       " '00e03u',\n",
       " '00e4',\n",
       " '00est',\n",
       " '00euro',\n",
       " '00faabobqaatwuaafafaabrbqaauguaafmfaabubqaavquaafyfaabxbqaawauaafkfaababqaawwuaafwfaabdbqaaxguaaf8faabgbqaayquaagifaabjbqaazauaagufaabmbqaazwuaaggfaabpbqaaaguaagsfaabsbqaabquaag4faabvbqaacauaahefaabybqaacwuaahqfaab1bqaadguaahcfaab4bqaaequaahofaab7bqaafauaah0faab',\n",
       " '00ff',\n",
       " '00ffff',\n",
       " '00for',\n",
       " '00golden',\n",
       " '00h',\n",
       " '00i',\n",
       " '00in',\n",
       " '00jan',\n",
       " '00ms',\n",
       " '00msgraphic',\n",
       " '00multiple',\n",
       " '00numbers',\n",
       " '00p',\n",
       " '00pm',\n",
       " '00pmemu',\n",
       " '00pmregistration',\n",
       " '00pmthe',\n",
       " '00pmweir',\n",
       " '00pmwhile',\n",
       " '00pnear',\n",
       " '00r',\n",
       " '00readme',\n",
       " '00secondary',\n",
       " '00shipping',\n",
       " '00subject',\n",
       " '00the',\n",
       " '00tim',\n",
       " '00time',\n",
       " '00total',\n",
       " '00u',\n",
       " '00usd',\n",
       " '00use',\n",
       " '00v',\n",
       " '00vga',\n",
       " '00what',\n",
       " '00which',\n",
       " '00x0c',\n",
       " '00x0f',\n",
       " '00you',\n",
       " '00z',\n",
       " '00以後',\n",
       " '00您在做什麼',\n",
       " '01',\n",
       " '010',\n",
       " '0100',\n",
       " '01000000',\n",
       " '0100007f',\n",
       " '01002413',\n",
       " '0100a8c0',\n",
       " '0100after',\n",
       " '0100d3',\n",
       " '0100from',\n",
       " '0100hello',\n",
       " '0100hi',\n",
       " '0100jonathan',\n",
       " '0100lee',\n",
       " '0100message',\n",
       " '0100mime',\n",
       " '0100ok',\n",
       " '0100on',\n",
       " '0100organization',\n",
       " '0100reply',\n",
       " '0100subject',\n",
       " '0100to',\n",
       " '0101',\n",
       " '0101e',\n",
       " '0102',\n",
       " '0103',\n",
       " '010307',\n",
       " '0105',\n",
       " '0106',\n",
       " '01062',\n",
       " '01063',\n",
       " '01063voice',\n",
       " '0106no',\n",
       " '0107',\n",
       " '010703',\n",
       " '010718',\n",
       " '0108',\n",
       " '010918',\n",
       " '0109toc3int',\n",
       " '010a',\n",
       " '010amicrosoft',\n",
       " '010kp',\n",
       " '010nl',\n",
       " '010ov',\n",
       " '011',\n",
       " '0110',\n",
       " '0111',\n",
       " '0112pactl',\n",
       " '0112servo_port',\n",
       " '01132',\n",
       " '0113tflg1',\n",
       " '0114',\n",
       " '0114f',\n",
       " '01155',\n",
       " '0115518009',\n",
       " '011557est',\n",
       " '0115la',\n",
       " '0115servo_disable',\n",
       " '0115tel',\n",
       " '0116349',\n",
       " '0116349proposal',\n",
       " '0117',\n",
       " '01184',\n",
       " '011a',\n",
       " '011aapple',\n",
       " '011commercial',\n",
       " '011fd',\n",
       " '011nl',\n",
       " '011ov',\n",
       " '012',\n",
       " '0120',\n",
       " '012002',\n",
       " '01223',\n",
       " '0123',\n",
       " '012437',\n",
       " '0125',\n",
       " '0126phone',\n",
       " '0128',\n",
       " '012amultiple',\n",
       " '012br',\n",
       " '012fd',\n",
       " '012mk',\n",
       " '013',\n",
       " '0130',\n",
       " '01309',\n",
       " '01311',\n",
       " '0133',\n",
       " '0133info',\n",
       " '0133net',\n",
       " '0136716296',\n",
       " '0138',\n",
       " '01392',\n",
       " '0139648437',\n",
       " '013br',\n",
       " '013fd',\n",
       " '013hn',\n",
       " '013kp',\n",
       " '013mk',\n",
       " '014',\n",
       " '01406',\n",
       " '01409',\n",
       " ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the fitted vocabulary\n",
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform training data into a 'document-term matrix'\n",
    "X_train_dtm = vect.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# equivalently: combine fit and transform into a single step\n",
    "X_train_dtm = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<23230x161925 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2305787 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the document-term matrix\n",
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7744x161925 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 744528 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 5: Building and evaluating a model\n",
    "\n",
    "We will use [multinomial Naive Bayes](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html):\n",
    "\n",
    "> The multinomial Naive Bayes classifier is suitable for classification with **discrete features** (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# import and instantiate a Multinomial Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36 ms, sys: 0 ns, total: 36 ms\n",
      "Wall time: 36.3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using X_train_dtm (timing it with an IPython \"magic command\")\n",
    "%time nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98476239669421484"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2967,    7],\n",
       "       [ 111, 4659]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      2974\n",
      "          1       1.00      0.98      0.99      4770\n",
      "\n",
      "avg / total       0.99      0.98      0.98      7744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00000000e+00,   1.00000000e+00,   1.73677105e-31, ...,\n",
       "         1.00000000e+00,   1.00000000e+00,   7.77424439e-01])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predicted probabilities for X_test_dtm (poorly calibrated)\n",
    "y_pred_prob = nb.predict_proba(X_test_dtm)[:, 1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99670526815912608"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate AUC\n",
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 7: Examining a model for further insight\n",
    "\n",
    "We will examine the our **trained Naive Bayes model** to calculate the approximate **\"spamminess\" of each token**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161925"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the vocabulary of X_train\n",
    "X_train_tokens = vect.get_feature_names()\n",
    "len(X_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '0000', '000000', '0000000', '00000000', '000000000', '00000000000000', '000000000000000000000000000000049999999999999e9', '0000000000000000000000000000000500000000000000e9', '0000000000000016666l', '0000000000000017d', '00000000000000e', '000000000000received', '000000000001received', '0000000001d0', '0000000001l0', '0000000010000000004l0', '0000000016', '000000001d0', '00000000message', '00000000x', '00000001', '00000001content', '00000001irdecode', '00000004', '00000010', '00000010pwm', '00000011', '00000049', '0000005', '0000006hz', '000000eb', '000001', '00000100', '00000100shaftencoder', '000001bdaaa0', '000001bdb744', '000001bdcaf3', '000001c642d0', '000001c64310', '000001c64585', '000001c64615', '000001c64641', '000001c6465f', '000001c6468e', '0000020', '0000040', '0000040b', '0000040c']\n"
     ]
    }
   ],
   "source": [
    "# examine the first 50 tokens\n",
    "print(X_train_tokens[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['３ｄバーチャルｓｅｘメーカー', '４名紹介http', '４月度新規メンバー様応援企画パーティー開催予定', '４月２３日', '５月までのようなので興味のある方はお早めに', '５月中週末３人か４人ぐらいで', '５００円分のポイントが完全無料で自動追加されます', '６名のみとなります', 'ａ型', 'ａ美様現在未亡人でいらっしゃいます', 'ｂ９６', 'ｆカップ', 'ｇａｌ誌多数掲載', 'ｇｏｏｄ', 'ｇｒａｎｄｅｅ', 'ｇｒａｎｄｅｅの理念やシステムのご紹介', 'ｇｗこそ出会いのチャンスhttp', 'ｇｗです', 'ｇｗはこういう女の子と過ごしたいっす', 'ｇｗ特典あり', 'ｈなこと大好きな人ばかり', 'ｈな女の子が多いので', 'ｈな欲望や願望を胸に秘め', 'ｈにそんなに興味なかったのと少し怖いのもあるため', 'ｈのお相手しただけで', 'ｈゲームメーカーの決定版', 'ｈ度', 'ｈ目的の出会いも簡単です', 'ｈ８６', 'ｋ村', 'ｍ子様セーリングクルーザーをお持ちで', 'ｍ字開脚オナニーを机の下から盗撮', 'ｍａｉｌでのサポートは２４時間対応です', 'ｎ藤', 'ｏｌ', 'ｐｃ', 'ｐｃから簡単プロフィール作成', 'ｓクラス専門店', 'ｓ子様秘密が条件で', 'ｓｅｘを求めている', 'ｓｅｘを求めているのです', 'ｓｍ', 'ｔ165', 'ｔバックは', 'ｔバックはいていたらおならが左右に分散するのでなんか変な感じですけどね', 'ｔバックを購入しました', 'ｔ島', 'ｔ谷', 'ｗ６２', 'ｙ里様お互いがくつろげるような']\n"
     ]
    }
   ],
   "source": [
    "# examine the last 50 tokens\n",
    "print(X_train_tokens[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.00900000e+03,   3.90000000e+02,   3.76000000e+02, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  3.63700000e+03,   5.30400000e+03,   0.00000000e+00, ...,\n",
       "          2.00000000e+00,   1.00000000e+00,   2.00000000e+00]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes counts the number of times each token appears in each class\n",
    "nb.feature_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 161925)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows represent classes, columns represent tokens\n",
    "nb.feature_count_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2009.,   390.,   376., ...,     0.,     0.,     0.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of times each token appears across all HAM messages\n",
    "ham_token_count = nb.feature_count_[0, :]\n",
    "ham_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.63700000e+03,   5.30400000e+03,   0.00000000e+00, ...,\n",
       "         2.00000000e+00,   1.00000000e+00,   2.00000000e+00])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of times each token appears across all SPAM messages\n",
    "spam_token_count = nb.feature_count_[1, :]\n",
    "spam_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>2009.0</td>\n",
       "      <td>3637.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>390.0</td>\n",
       "      <td>5304.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000</th>\n",
       "      <td>376.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000</th>\n",
       "      <td>50.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000000</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ham    spam\n",
       "token                  \n",
       "00       2009.0  3637.0\n",
       "000       390.0  5304.0\n",
       "0000      376.0     0.0\n",
       "000000     50.0    62.0\n",
       "0000000     1.0     0.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DataFrame of tokens with their separate ham and spam counts\n",
    "tokens = pd.DataFrame({'token':X_train_tokens, 'ham':ham_token_count, 'spam':spam_token_count}).set_index('token')\n",
    "tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bench</th>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bitmapsand</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gosses</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tome</th>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ham  spam\n",
       "token                 \n",
       "bench       14.0   7.0\n",
       "bitmapsand   1.0   0.0\n",
       "gosses       2.0   0.0\n",
       "tome         4.0   9.0\n",
       "1388         3.0   0.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine 5 random DataFrame rows\n",
    "tokens.sample(5, random_state=427)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8720.,  14510.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes counts the number of observations in each class\n",
    "nb.class_count_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Before we can calculate the \"spamminess\" of each token, we need to avoid **dividing by zero** and account for the **class imbalance**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bench</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bitmapsand</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gosses</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tome</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ham  spam\n",
       "token                 \n",
       "bench       15.0   8.0\n",
       "bitmapsand   2.0   1.0\n",
       "gosses       3.0   1.0\n",
       "tome         5.0  10.0\n",
       "1388         4.0   1.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add 1 to ham and spam counts to avoid dividing by 0\n",
    "tokens['ham'] = tokens.ham + 1\n",
    "tokens['spam'] = tokens.spam + 1\n",
    "tokens.sample(5, random_state=427)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bench</th>\n",
       "      <td>0.001720</td>\n",
       "      <td>0.000551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bitmapsand</th>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gosses</th>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tome</th>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.000689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ham      spam\n",
       "token                         \n",
       "bench       0.001720  0.000551\n",
       "bitmapsand  0.000229  0.000069\n",
       "gosses      0.000344  0.000069\n",
       "tome        0.000573  0.000689\n",
       "1388        0.000459  0.000069"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the ham and spam counts into frequencies\n",
    "tokens['ham'] = tokens.ham / nb.class_count_[0]\n",
    "tokens['spam'] = tokens.spam / nb.class_count_[1]\n",
    "tokens.sample(5, random_state=427)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "      <th>spam_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bench</th>\n",
       "      <td>0.001720</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.320515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bitmapsand</th>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.300482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gosses</th>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.200322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tome</th>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>1.201930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.150241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ham      spam  spam_ratio\n",
       "token                                     \n",
       "bench       0.001720  0.000551    0.320515\n",
       "bitmapsand  0.000229  0.000069    0.300482\n",
       "gosses      0.000344  0.000069    0.200322\n",
       "tome        0.000573  0.000689    1.201930\n",
       "1388        0.000459  0.000069    0.150241"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the ratio of spam-to-ham for each token\n",
    "tokens['spam_ratio'] = tokens.spam / tokens.ham\n",
    "tokens.sample(5, random_state=427)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "      <th>spam_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>product_table</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.640662</td>\n",
       "      <td>5586.569263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15px</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.201447</td>\n",
       "      <td>1756.620262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0px</th>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.726465</td>\n",
       "      <td>1583.692626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proms</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.160510</td>\n",
       "      <td>1399.647140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>professionaladobe</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.160510</td>\n",
       "      <td>1399.647140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hereopt</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.125844</td>\n",
       "      <td>1097.361819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.122605</td>\n",
       "      <td>1069.116471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95more</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.120400</td>\n",
       "      <td>1049.885596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compacted_description</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.120400</td>\n",
       "      <td>1049.885596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewsretail</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.120400</td>\n",
       "      <td>1049.885596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00you</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.120400</td>\n",
       "      <td>1049.885596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoodia</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.109097</td>\n",
       "      <td>951.327360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs2</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.104893</td>\n",
       "      <td>914.668504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cantex</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.102481</td>\n",
       "      <td>893.634735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13px</th>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.201861</td>\n",
       "      <td>880.113025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>無料</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.098691</td>\n",
       "      <td>860.581668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weightzipping</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.081668</td>\n",
       "      <td>712.143349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bestsellers</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.081392</td>\n",
       "      <td>709.739490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sp_cont</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.080289</td>\n",
       "      <td>700.124052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5adobe</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.080289</td>\n",
       "      <td>700.124052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greylink</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.080289</td>\n",
       "      <td>700.124052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compacted_price</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.080289</td>\n",
       "      <td>700.124052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compacted_image</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.080289</td>\n",
       "      <td>700.124052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proadobe</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.080289</td>\n",
       "      <td>700.124052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00c</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.080289</td>\n",
       "      <td>700.124052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collectionadobe</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.080289</td>\n",
       "      <td>700.124052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rolex</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.058580</td>\n",
       "      <td>510.820124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discreet</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.058442</td>\n",
       "      <td>509.618194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bz</th>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.116678</td>\n",
       "      <td>508.716747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>herewant</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.055686</td>\n",
       "      <td>485.579600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fred</th>\n",
       "      <td>0.060894</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.001132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voltage</th>\n",
       "      <td>0.061124</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.001128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timedx</th>\n",
       "      <td>0.062729</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.001099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computing</th>\n",
       "      <td>0.063073</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.001093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analog</th>\n",
       "      <td>0.067890</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.001015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8babaaaaambg8afgd</th>\n",
       "      <td>0.068693</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.001003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weaeaaaacygdwawap</th>\n",
       "      <td>0.069037</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ir</th>\n",
       "      <td>0.069495</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>servo</th>\n",
       "      <td>0.070872</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sonar</th>\n",
       "      <td>0.071330</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starship</th>\n",
       "      <td>0.072706</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aqaqaaaajgypabya</th>\n",
       "      <td>0.075917</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgp</th>\n",
       "      <td>0.076720</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nil</th>\n",
       "      <td>0.231193</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sep</th>\n",
       "      <td>0.081307</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sensor</th>\n",
       "      <td>0.082339</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>routing</th>\n",
       "      <td>0.083830</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thu</th>\n",
       "      <td>0.087844</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>motors</th>\n",
       "      <td>0.095298</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linux</th>\n",
       "      <td>0.097592</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>libimlib</th>\n",
       "      <td>0.099197</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robot</th>\n",
       "      <td>0.113876</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>output</th>\n",
       "      <td>0.116628</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ribbon</th>\n",
       "      <td>0.121674</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>port</th>\n",
       "      <td>0.147248</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nodes</th>\n",
       "      <td>0.163532</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>node</th>\n",
       "      <td>0.166514</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>handy</th>\n",
       "      <td>0.167317</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cert</th>\n",
       "      <td>0.192775</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hb</th>\n",
       "      <td>0.193693</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161925 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            ham      spam   spam_ratio\n",
       "token                                                 \n",
       "product_table          0.000115  0.640662  5586.569263\n",
       "15px                   0.000115  0.201447  1756.620262\n",
       "0px                    0.000459  0.726465  1583.692626\n",
       "proms                  0.000115  0.160510  1399.647140\n",
       "professionaladobe      0.000115  0.160510  1399.647140\n",
       "hereopt                0.000115  0.125844  1097.361819\n",
       "fff                    0.000115  0.122605  1069.116471\n",
       "95more                 0.000115  0.120400  1049.885596\n",
       "compacted_description  0.000115  0.120400  1049.885596\n",
       "reviewsretail          0.000115  0.120400  1049.885596\n",
       "00you                  0.000115  0.120400  1049.885596\n",
       "hoodia                 0.000115  0.109097   951.327360\n",
       "cs2                    0.000115  0.104893   914.668504\n",
       "cantex                 0.000115  0.102481   893.634735\n",
       "13px                   0.000229  0.201861   880.113025\n",
       "無料                     0.000115  0.098691   860.581668\n",
       "weightzipping          0.000115  0.081668   712.143349\n",
       "bestsellers            0.000115  0.081392   709.739490\n",
       "sp_cont                0.000115  0.080289   700.124052\n",
       "5adobe                 0.000115  0.080289   700.124052\n",
       "greylink               0.000115  0.080289   700.124052\n",
       "compacted_price        0.000115  0.080289   700.124052\n",
       "compacted_image        0.000115  0.080289   700.124052\n",
       "proadobe               0.000115  0.080289   700.124052\n",
       "00c                    0.000115  0.080289   700.124052\n",
       "collectionadobe        0.000115  0.080289   700.124052\n",
       "rolex                  0.000115  0.058580   510.820124\n",
       "discreet               0.000115  0.058442   509.618194\n",
       "bz                     0.000229  0.116678   508.716747\n",
       "herewant               0.000115  0.055686   485.579600\n",
       "...                         ...       ...          ...\n",
       "fred                   0.060894  0.000069     0.001132\n",
       "voltage                0.061124  0.000069     0.001128\n",
       "timedx                 0.062729  0.000069     0.001099\n",
       "computing              0.063073  0.000069     0.001093\n",
       "analog                 0.067890  0.000069     0.001015\n",
       "8babaaaaambg8afgd      0.068693  0.000069     0.001003\n",
       "weaeaaaacygdwawap      0.069037  0.000069     0.000998\n",
       "ir                     0.069495  0.000069     0.000992\n",
       "servo                  0.070872  0.000069     0.000972\n",
       "sonar                  0.071330  0.000069     0.000966\n",
       "starship               0.072706  0.000069     0.000948\n",
       "aqaqaaaajgypabya       0.075917  0.000069     0.000908\n",
       "pgp                    0.076720  0.000069     0.000898\n",
       "nil                    0.231193  0.000207     0.000894\n",
       "sep                    0.081307  0.000069     0.000848\n",
       "sensor                 0.082339  0.000069     0.000837\n",
       "routing                0.083830  0.000069     0.000822\n",
       "thu                    0.087844  0.000069     0.000785\n",
       "motors                 0.095298  0.000069     0.000723\n",
       "linux                  0.097592  0.000069     0.000706\n",
       "libimlib               0.099197  0.000069     0.000695\n",
       "robot                  0.113876  0.000069     0.000605\n",
       "output                 0.116628  0.000069     0.000591\n",
       "ribbon                 0.121674  0.000069     0.000566\n",
       "port                   0.147248  0.000069     0.000468\n",
       "nodes                  0.163532  0.000069     0.000421\n",
       "node                   0.166514  0.000069     0.000414\n",
       "handy                  0.167317  0.000069     0.000412\n",
       "cert                   0.192775  0.000069     0.000358\n",
       "hb                     0.193693  0.000069     0.000356\n",
       "\n",
       "[161925 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the DataFrame sorted by spam_ratio\n",
    "# note: use sort() instead of sort_values() for pandas 0.16.2 and earlier\n",
    "tokens.sort_values('spam_ratio', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.449971806277802"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up the spam_ratio for a given token\n",
    "tokens.loc['adobe', 'spam_ratio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 9: Tuning the vectorizer (Challenge)\n",
    "\n",
    "Thus far, we have been using the default parameters of [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show default parameters for CountVectorizer\n",
    "vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "However, the vectorizer is worth tuning, just like a model is worth tuning! Here are a few parameters that you might want to tune:\n",
    "\n",
    "- **stop_words:** string {'english'}, list, or None (default)\n",
    "    - If 'english', a built-in stop word list for English is used.\n",
    "    - If a list, that list is assumed to contain stop words, all of which will be removed from the resulting tokens.\n",
    "    - If None, no stop words will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# remove English stop words\n",
    "vect = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "- **ngram_range:** tuple (min_n, max_n), default=(1, 1)\n",
    "    - The lower and upper boundary of the range of n-values for different n-grams to be extracted.\n",
    "    - All values of n such that min_n <= n <= max_n will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# include 1-grams and 2-grams\n",
    "vect = CountVectorizer(ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "- **max_df:** float in range [0.0, 1.0] or int, default=1.0\n",
    "    - When building the vocabulary, ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words).\n",
    "    - If float, the parameter represents a proportion of documents.\n",
    "    - If integer, the parameter represents an absolute count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# ignore terms that appear in more than 50% of the documents\n",
    "vect = CountVectorizer(max_df=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "- **min_df:** float in range [0.0, 1.0] or int, default=1\n",
    "    - When building the vocabulary, ignore terms that have a document frequency strictly lower than the given threshold. (This value is also called \"cut-off\" in the literature.)\n",
    "    - If float, the parameter represents a proportion of documents.\n",
    "    - If integer, the parameter represents an absolute count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# only keep terms that appear in at least 2 documents\n",
    "vect = CountVectorizer(min_df=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "**Guidelines for tuning CountVectorizer:**\n",
    "\n",
    "- Use your knowledge of the **problem** and the **text**, and your understanding of the **tuning parameters**, to help you decide what parameters to tune and how to tune them.\n",
    "\n",
    "Tasks:\n",
    "1. **Experiment**, and let the data tell you the best approach!\n",
    "2. Try to reduce or increase the features and get a better score on the previous model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23230, 2563581)\n",
      "(7744, 2563581)\n",
      "(23230,)\n",
      "(7744,)\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(stop_words='english', ngram_range=(1, 3), max_df=0.5)\n",
    "X_trimmed = vect.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_trimmed, y, random_state=427)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2563581"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tokens = vect.get_feature_names()\n",
    "len(X_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9870    0.9980    0.9925      2974\n",
      "          1     0.9987    0.9918    0.9953      4770\n",
      "\n",
      "avg / total     0.9942    0.9942    0.9942      7744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "print(classification_report(y_test, nb.predict(X_test), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_token_count = nb.feature_count_[0, :]\n",
    "spam_token_count = nb.feature_count_[1, :]\n",
    "tokens = pd.DataFrame({'token':X_train_tokens, 'ham':ham_token_count, 'spam':spam_token_count}).set_index('token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadrian/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:4: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "      <th>spam_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hb</th>\n",
       "      <td>1689.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cert</th>\n",
       "      <td>1681.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nil nil</th>\n",
       "      <td>1615.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>handy</th>\n",
       "      <td>1459.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>node</th>\n",
       "      <td>1452.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nodes</th>\n",
       "      <td>1426.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nil nil nil</th>\n",
       "      <td>1369.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>handy board</th>\n",
       "      <td>1308.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>port</th>\n",
       "      <td>1284.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usd edu</th>\n",
       "      <td>1155.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ribbon</th>\n",
       "      <td>1061.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ribbon campaign</th>\n",
       "      <td>1033.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign html</th>\n",
       "      <td>1026.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign html mail</th>\n",
       "      <td>1026.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ribbon campaign html</th>\n",
       "      <td>1026.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ascii ribbon</th>\n",
       "      <td>1017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>output</th>\n",
       "      <td>1017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ascii ribbon campaign</th>\n",
       "      <td>1017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jonathan ascii ribbon</th>\n",
       "      <td>1010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jonathan ascii</th>\n",
       "      <td>1010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robot</th>\n",
       "      <td>993.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>libimlib</th>\n",
       "      <td>865.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linux</th>\n",
       "      <td>851.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>motors</th>\n",
       "      <td>831.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>women studies</th>\n",
       "      <td>799.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thu</th>\n",
       "      <td>766.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>routing</th>\n",
       "      <td>731.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sensor</th>\n",
       "      <td>718.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sep</th>\n",
       "      <td>709.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nil</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.001488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>info hereopt campaign</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1826.0</td>\n",
       "      <td>1826.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hereopt campaign website</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1826.0</td>\n",
       "      <td>1826.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hereopt</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1826.0</td>\n",
       "      <td>1826.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0px padding</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4089.0</td>\n",
       "      <td>2044.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windows xp proms</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2329.0</td>\n",
       "      <td>2329.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>professionaladobe</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2329.0</td>\n",
       "      <td>2329.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xp proms</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2329.0</td>\n",
       "      <td>2329.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proms office 2003</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2329.0</td>\n",
       "      <td>2329.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proms office</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2329.0</td>\n",
       "      <td>2329.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proms</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2329.0</td>\n",
       "      <td>2329.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xp proms office</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2329.0</td>\n",
       "      <td>2329.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price 69 95</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2329.0</td>\n",
       "      <td>2329.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price 69</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2329.0</td>\n",
       "      <td>2329.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69 95 add</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2329.0</td>\n",
       "      <td>2329.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium border medium</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2329.0</td>\n",
       "      <td>2329.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium border</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2329.0</td>\n",
       "      <td>2329.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>border medium</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2329.0</td>\n",
       "      <td>2329.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>info microsoft</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2329.0</td>\n",
       "      <td>2329.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left 0px padding</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2337.0</td>\n",
       "      <td>2337.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69 95</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2559.0</td>\n",
       "      <td>2559.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0px</th>\n",
       "      <td>4.0</td>\n",
       "      <td>10541.0</td>\n",
       "      <td>2635.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ddd 1px solid</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2911.0</td>\n",
       "      <td>2911.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ddd 1px</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2911.0</td>\n",
       "      <td>2911.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>padding left 0px</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2919.0</td>\n",
       "      <td>2919.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left 0px</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2923.0</td>\n",
       "      <td>2923.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15px</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2923.0</td>\n",
       "      <td>2923.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95 add cart</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3493.0</td>\n",
       "      <td>3493.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95 add</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3493.0</td>\n",
       "      <td>3493.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>add cart</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3493.0</td>\n",
       "      <td>3493.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_table</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9296.0</td>\n",
       "      <td>9296.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2563581 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             ham     spam   spam_ratio\n",
       "token                                                 \n",
       "hb                        1689.0      1.0     0.000592\n",
       "cert                      1681.0      1.0     0.000595\n",
       "nil nil                   1615.0      1.0     0.000619\n",
       "handy                     1459.0      1.0     0.000685\n",
       "node                      1452.0      1.0     0.000689\n",
       "nodes                     1426.0      1.0     0.000701\n",
       "nil nil nil               1369.0      1.0     0.000730\n",
       "handy board               1308.0      1.0     0.000765\n",
       "port                      1284.0      1.0     0.000779\n",
       "usd edu                   1155.0      1.0     0.000866\n",
       "ribbon                    1061.0      1.0     0.000943\n",
       "ribbon campaign           1033.0      1.0     0.000968\n",
       "campaign html             1026.0      1.0     0.000975\n",
       "campaign html mail        1026.0      1.0     0.000975\n",
       "ribbon campaign html      1026.0      1.0     0.000975\n",
       "ascii ribbon              1017.0      1.0     0.000983\n",
       "output                    1017.0      1.0     0.000983\n",
       "ascii ribbon campaign     1017.0      1.0     0.000983\n",
       "jonathan ascii ribbon     1010.0      1.0     0.000990\n",
       "jonathan ascii            1010.0      1.0     0.000990\n",
       "robot                      993.0      1.0     0.001007\n",
       "libimlib                   865.0      1.0     0.001156\n",
       "linux                      851.0      1.0     0.001175\n",
       "motors                     831.0      1.0     0.001203\n",
       "women studies              799.0      1.0     0.001252\n",
       "thu                        766.0      1.0     0.001305\n",
       "routing                    731.0      1.0     0.001368\n",
       "sensor                     718.0      1.0     0.001393\n",
       "sep                        709.0      1.0     0.001410\n",
       "nil                       2016.0      3.0     0.001488\n",
       "...                          ...      ...          ...\n",
       "info hereopt campaign        1.0   1826.0  1826.000000\n",
       "hereopt campaign website     1.0   1826.0  1826.000000\n",
       "hereopt                      1.0   1826.0  1826.000000\n",
       "0px padding                  2.0   4089.0  2044.500000\n",
       "windows xp proms             1.0   2329.0  2329.000000\n",
       "professionaladobe            1.0   2329.0  2329.000000\n",
       "xp proms                     1.0   2329.0  2329.000000\n",
       "proms office 2003            1.0   2329.0  2329.000000\n",
       "proms office                 1.0   2329.0  2329.000000\n",
       "proms                        1.0   2329.0  2329.000000\n",
       "xp proms office              1.0   2329.0  2329.000000\n",
       "price 69 95                  1.0   2329.0  2329.000000\n",
       "price 69                     1.0   2329.0  2329.000000\n",
       "69 95 add                    1.0   2329.0  2329.000000\n",
       "medium border medium         1.0   2329.0  2329.000000\n",
       "medium border                1.0   2329.0  2329.000000\n",
       "border medium                1.0   2329.0  2329.000000\n",
       "info microsoft               1.0   2329.0  2329.000000\n",
       "left 0px padding             1.0   2337.0  2337.000000\n",
       "69 95                        1.0   2559.0  2559.000000\n",
       "0px                          4.0  10541.0  2635.250000\n",
       "ddd 1px solid                1.0   2911.0  2911.000000\n",
       "ddd 1px                      1.0   2911.0  2911.000000\n",
       "padding left 0px             1.0   2919.0  2919.000000\n",
       "left 0px                     1.0   2923.0  2923.000000\n",
       "15px                         1.0   2923.0  2923.000000\n",
       "95 add cart                  1.0   3493.0  3493.000000\n",
       "95 add                       1.0   3493.0  3493.000000\n",
       "add cart                     1.0   3493.0  3493.000000\n",
       "product_table                1.0   9296.0  9296.000000\n",
       "\n",
       "[2563581 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['ham'] = tokens.ham + 1\n",
    "tokens['spam'] = tokens.spam + 1\n",
    "tokens['spam_ratio'] = tokens.spam / tokens.ham\n",
    "tokens.sort('spam_ratio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 10: Tuning the Laplacian Correction Factor (Challenge)\n",
    "\n",
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html):\n",
    "\n",
    "> class sklearn.naive_bayes.MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None)\n",
    "\n",
    "> Parameters:\t\n",
    "alpha : float, optional (default=1.0)\n",
    "Additive (Laplace/Lidstone) smoothing parameter (0 for no smoothing).\n",
    "\n",
    "One of the parameters that we can tune in training a Multinomial Naive Bayes Classifier is the Laplacian Correction Factor.\n",
    "\n",
    "Tasks:\n",
    "1. Tweak the correction factor from 0-10, thus training multiple classifiers.\n",
    "2. Plot the precision-recall curves for these classifiers to compare and contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [MultinomialNB(alpha=i) for i in range(0, 10, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadrian/anaconda3/lib/python3.5/site-packages/sklearn/naive_bayes.py:699: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = (np.log(smoothed_fc) -\n"
     ]
    }
   ],
   "source": [
    "for i in classifiers:\n",
    "    i.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBwLYHKZUzMKzAAAAAElEQVQ1rwYeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbc4796eeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "for i in classifiers:\n",
    "    precision, recall, _ = precision_recall_curve(y_test.ravel(),\n",
    "        i.predict(X_test).ravel())\n",
    "    average_precision = average_precision_score(y_test, i.predict(X_test).ravel(),\n",
    "                                                         average=\"micro\")\n",
    "    plot(recall, precision,\n",
    "             label='micro-average Precision-recall curve (area = {0:0.2f})'\n",
    "                   ''.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8966    0.9997    0.9453      2974\n",
      "          1     0.9998    0.9281    0.9626      4770\n",
      "\n",
      "avg / total     0.9601    0.9556    0.9560      7744\n",
      "\n",
      "1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9870    0.9980    0.9925      2974\n",
      "          1     0.9987    0.9918    0.9953      4770\n",
      "\n",
      "avg / total     0.9942    0.9942    0.9942      7744\n",
      "\n",
      "2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9854    0.9973    0.9913      2974\n",
      "          1     0.9983    0.9908    0.9945      4770\n",
      "\n",
      "avg / total     0.9933    0.9933    0.9933      7744\n",
      "\n",
      "3\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9847    0.9966    0.9906      2974\n",
      "          1     0.9979    0.9904    0.9941      4770\n",
      "\n",
      "avg / total     0.9928    0.9928    0.9928      7744\n",
      "\n",
      "4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9841    0.9966    0.9903      2974\n",
      "          1     0.9979    0.9899    0.9939      4770\n",
      "\n",
      "avg / total     0.9926    0.9925    0.9925      7744\n",
      "\n",
      "5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9837    0.9966    0.9901      2974\n",
      "          1     0.9979    0.9897    0.9938      4770\n",
      "\n",
      "avg / total     0.9925    0.9924    0.9924      7744\n",
      "\n",
      "6\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9828    0.9966    0.9896      2974\n",
      "          1     0.9979    0.9891    0.9935      4770\n",
      "\n",
      "avg / total     0.9921    0.9920    0.9920      7744\n",
      "\n",
      "7\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9811    0.9966    0.9888      2974\n",
      "          1     0.9979    0.9881    0.9929      4770\n",
      "\n",
      "avg / total     0.9914    0.9913    0.9914      7744\n",
      "\n",
      "8\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9808    0.9966    0.9887      2974\n",
      "          1     0.9979    0.9878    0.9928      4770\n",
      "\n",
      "avg / total     0.9913    0.9912    0.9912      7744\n",
      "\n",
      "9\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9808    0.9966    0.9887      2974\n",
      "          1     0.9979    0.9878    0.9928      4770\n",
      "\n",
      "avg / total     0.9913    0.9912    0.9912      7744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in classifiers:\n",
    "    print(i.get_params()['alpha'])\n",
    "    print(classification_report(y_test, i.predict(X_test),digits=4))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
