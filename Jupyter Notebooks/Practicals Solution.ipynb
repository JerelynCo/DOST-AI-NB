{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOST AI Summer School 2017\n",
    "# Multinomial Naive Bayes Spam Classifier\n",
    "\n",
    "#### Prepared by Jerelyn Co and Hadrian Paulo Lim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Practicals: Spam Filtering with Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Agenda\n",
    "\n",
    "2. Representing text as numerical data\n",
    "3. Reading a text-based dataset into pandas\n",
    "4. Vectorizing our dataset\n",
    "5. Building and evaluating a model\n",
    "6. Comparing models\n",
    "7. Examining a model for further insight\n",
    "9. Tuning the vectorizer (challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 1: Representing text as numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# example text for model training\n",
    "simple_train = ['call you tonight', 'Call me a cab', 'please call me... PLEASE!']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    "\n",
    "> Text Analysis is a major application field for machine learning algorithms. However the raw data, a sequence of symbols cannot be fed directly to the algorithms themselves as most of them expect **numerical feature vectors with a fixed size** rather than the **raw text documents with variable length**.\n",
    "\n",
    "We will use [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) to \"convert text into a matrix of token counts\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# import and instantiate CountVectorizer (with the default parameters)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learn the 'vocabulary' of the training data (occurs in-place)\n",
    "vect.fit(simple_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cab', 'call', 'me', 'please', 'tonight', 'you']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the fitted vocabulary\n",
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x6 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 9 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform training data into a 'document-term matrix'\n",
    "simple_train_dtm = vect.transform(simple_train)\n",
    "simple_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 1, 1],\n",
       "       [1, 1, 1, 0, 0, 0],\n",
       "       [0, 1, 1, 2, 0, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert sparse matrix to a dense matrix\n",
    "simple_train_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    0     1   0       0        1    1\n",
       "1    1     1   1       0        0    0\n",
       "2    0     1   1       2        0    0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(simple_train_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    "\n",
    "> In this scheme, features and samples are defined as follows:\n",
    "\n",
    "> - Each individual token occurrence frequency (normalized or not) is treated as a **feature**.\n",
    "> - The vector of all the token frequencies for a given document is considered a multivariate **sample**.\n",
    "\n",
    "> A **corpus of documents** can thus be represented by a matrix with **one row per document** and **one column per token** (e.g. word) occurring in the corpus.\n",
    "\n",
    "> We call **vectorization** the general process of turning a collection of text documents into numerical feature vectors. This specific strategy (tokenization, counting and normalization) is called the **Bag of Words** or \"Bag of n-grams\" representation. Documents are described by word occurrences while completely ignoring the relative position information of the words in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the type of the document-term matrix\n",
    "type(simple_train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 2)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 3)\t2\n"
     ]
    }
   ],
   "source": [
    "# examine the sparse matrix contents\n",
    "print(simple_train_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    "\n",
    "> As most documents will typically use a very small subset of the words used in the corpus, the resulting matrix will have **many feature values that are zeros** (typically more than 99% of them).\n",
    "\n",
    "> For instance, a collection of 10,000 short text documents (such as emails) will use a vocabulary with a size in the order of 100,000 unique words in total while each document will use 100 to 1000 unique words individually.\n",
    "\n",
    "> In order to be able to **store such a matrix in memory** but also to **speed up operations**, implementations will typically use a **sparse representation** such as the implementations available in the `scipy.sparse` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# example text for model testing\n",
    "simple_test = [\"please don't call me\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "In order to **make a prediction**, the new observation must have the **same features as the training observations**, both in number and meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data into a document-term matrix (using existing vocabulary)\n",
    "simple_test_dtm = vect.transform(simple_test)\n",
    "simple_test_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    0     1   1       1        0    0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(simple_test_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "**Summary:**\n",
    "\n",
    "- `vect.fit(train)` **learns the vocabulary** of the training data\n",
    "- `vect.transform(train)` uses the **fitted vocabulary** to build a document-term matrix from the training data\n",
    "- `vect.transform(test)` uses the **fitted vocabulary** to build a document-term matrix from the testing data (and **ignores tokens** it hasn't seen before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 3: Reading a text-based dataset into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# read file into pandas using a relative path\n",
    "path = 'data/spam_ham.csv'\n",
    "spam_ham = pd.read_csv(path, header=0, names=['label', 'location','message'])\n",
    "spam_ham.drop('location', axis=1, inplace=True)\n",
    "spam_ham.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30974, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the shape\n",
    "spam_ham.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>LUXURY WATCHES - BUY YOUR OWN ROLEX FOR ONLY $...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Academic Qualifications available from prestig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Greetings all. This is to verify your subscrip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>try chauncey may conferred the luscious not co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>It's quiet. Too quiet. Well, how about a straw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>It's working here. I have departed almost tota...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spam</td>\n",
       "      <td>The OIL sector is going crazy. This is our wee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spam</td>\n",
       "      <td>Little magic. Perfect weekends.http://othxu.rz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ham</td>\n",
       "      <td>Greetings all. This is a mass acknowledgement ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hi, L C P A X V V e I r m a A I v A o b n L A ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0  spam  LUXURY WATCHES - BUY YOUR OWN ROLEX FOR ONLY $...\n",
       "1  spam  Academic Qualifications available from prestig...\n",
       "2   ham  Greetings all. This is to verify your subscrip...\n",
       "3  spam  try chauncey may conferred the luscious not co...\n",
       "4   ham  It's quiet. Too quiet. Well, how about a straw...\n",
       "5   ham  It's working here. I have departed almost tota...\n",
       "6  spam  The OIL sector is going crazy. This is our wee...\n",
       "7  spam  Little magic. Perfect weekends.http://othxu.rz...\n",
       "8   ham  Greetings all. This is a mass acknowledgement ...\n",
       "9  spam  Hi, L C P A X V V e I r m a A I v A o b n L A ..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the first 10 rows\n",
    "spam_ham.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam    19280\n",
       "ham     11694\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the class distribution\n",
    "spam_ham.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# convert label to a numerical variable\n",
    "spam_ham['label_num'] = spam_ham.label.map({'ham':0, 'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>LUXURY WATCHES - BUY YOUR OWN ROLEX FOR ONLY $...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Academic Qualifications available from prestig...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Greetings all. This is to verify your subscrip...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>try chauncey may conferred the luscious not co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>It's quiet. Too quiet. Well, how about a straw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>It's working here. I have departed almost tota...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spam</td>\n",
       "      <td>The OIL sector is going crazy. This is our wee...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spam</td>\n",
       "      <td>Little magic. Perfect weekends.http://othxu.rz...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ham</td>\n",
       "      <td>Greetings all. This is a mass acknowledgement ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hi, L C P A X V V e I r m a A I v A o b n L A ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  label_num\n",
       "0  spam  LUXURY WATCHES - BUY YOUR OWN ROLEX FOR ONLY $...          1\n",
       "1  spam  Academic Qualifications available from prestig...          1\n",
       "2   ham  Greetings all. This is to verify your subscrip...          0\n",
       "3  spam  try chauncey may conferred the luscious not co...          1\n",
       "4   ham  It's quiet. Too quiet. Well, how about a straw...          0\n",
       "5   ham  It's working here. I have departed almost tota...          0\n",
       "6  spam  The OIL sector is going crazy. This is our wee...          1\n",
       "7  spam  Little magic. Perfect weekends.http://othxu.rz...          1\n",
       "8   ham  Greetings all. This is a mass acknowledgement ...          0\n",
       "9  spam  Hi, L C P A X V V e I r m a A I v A o b n L A ...          1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that the conversion worked\n",
    "spam_ham.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30974,)\n",
      "(30974,)\n"
     ]
    }
   ],
   "source": [
    "# how to define X and y (from the SMS data) for use with COUNTVECTORIZER\n",
    "X = spam_ham.message\n",
    "y = spam_ham.label_num\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23230,)\n",
      "(7744,)\n",
      "(23230,)\n",
      "(7744,)\n"
     ]
    }
   ],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=427)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 4: Vectorizing our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# instantiate the vectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learn training data vocabulary, then use it to create a document-term matrix\n",
    "vect.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '0000',\n",
       " '000000',\n",
       " '0000000',\n",
       " '00000000',\n",
       " '000000000',\n",
       " '00000000000000',\n",
       " '000000000000000000000000000000049999999999999e9',\n",
       " '0000000000000000000000000000000500000000000000e9',\n",
       " '0000000000000016666l',\n",
       " '0000000000000017d',\n",
       " '00000000000000e',\n",
       " '000000000000received',\n",
       " '000000000001received',\n",
       " '0000000001d0',\n",
       " '0000000001l0',\n",
       " '0000000010000000004l0',\n",
       " '0000000016',\n",
       " '000000001d0',\n",
       " '00000000message',\n",
       " '00000000x',\n",
       " '00000001',\n",
       " '00000001content',\n",
       " '00000001irdecode',\n",
       " '00000004',\n",
       " '00000010',\n",
       " '00000010pwm',\n",
       " '00000011',\n",
       " '00000049',\n",
       " '0000005',\n",
       " '0000006hz',\n",
       " '000000eb',\n",
       " '000001',\n",
       " '00000100',\n",
       " '00000100shaftencoder',\n",
       " '000001bdaaa0',\n",
       " '000001bdb744',\n",
       " '000001bdcaf3',\n",
       " '000001c642d0',\n",
       " '000001c64310',\n",
       " '000001c64585',\n",
       " '000001c64615',\n",
       " '000001c64641',\n",
       " '000001c6465f',\n",
       " '000001c6468e',\n",
       " '0000020',\n",
       " '0000040',\n",
       " '0000040b',\n",
       " '0000040c',\n",
       " '000005',\n",
       " '0000060',\n",
       " '00000dd0',\n",
       " '00001',\n",
       " '000010',\n",
       " '0000100',\n",
       " '00001000',\n",
       " '00001004',\n",
       " '00001008',\n",
       " '0000100c',\n",
       " '00001010',\n",
       " '00001014',\n",
       " '00001018',\n",
       " '0000101c',\n",
       " '00001023',\n",
       " '00001026',\n",
       " '00001028',\n",
       " '0000102c',\n",
       " '00001030',\n",
       " '00001034',\n",
       " '00001038',\n",
       " '0000103e',\n",
       " '00001040',\n",
       " '00001044',\n",
       " '00001048',\n",
       " '0000104c',\n",
       " '00001050',\n",
       " '00001054',\n",
       " '0000105a',\n",
       " '0000105ci',\n",
       " '0000120',\n",
       " '0000140',\n",
       " '0000160',\n",
       " '00001808',\n",
       " '0000180cmain',\n",
       " '0000200',\n",
       " '0000220',\n",
       " '0000240',\n",
       " '0000260',\n",
       " '0000300',\n",
       " '00003001722',\n",
       " '000031',\n",
       " '0000320',\n",
       " '0000340',\n",
       " '0000360',\n",
       " '00004',\n",
       " '0000400',\n",
       " '0000420',\n",
       " '0000440',\n",
       " '000046',\n",
       " '0000460',\n",
       " '0000500',\n",
       " '0000504',\n",
       " '000061',\n",
       " '000066',\n",
       " '000076',\n",
       " '000092',\n",
       " '00009800',\n",
       " '00009804',\n",
       " '0000bi',\n",
       " '0000bytes',\n",
       " '0000comment',\n",
       " '0000content',\n",
       " '0000d5',\n",
       " '0000date',\n",
       " '0000david',\n",
       " '0000delivered',\n",
       " '0000ff',\n",
       " '0000from',\n",
       " '0000importance',\n",
       " '0000in',\n",
       " '0000institute',\n",
       " '0000instituteof0000',\n",
       " '0000message',\n",
       " '0000mime',\n",
       " '0000nline',\n",
       " '0000nology',\n",
       " '0000nology404',\n",
       " '0000of',\n",
       " '0000organization',\n",
       " '0000our',\n",
       " '0000received',\n",
       " '0000reply',\n",
       " '0000scott',\n",
       " '0000to',\n",
       " '0000x',\n",
       " '0001',\n",
       " '00010000',\n",
       " '000101376290',\n",
       " '000101bdcbb7',\n",
       " '00010246',\n",
       " '00010246ebx',\n",
       " '000107',\n",
       " '00011',\n",
       " '00014',\n",
       " '0001_mayprod',\n",
       " '0001jn',\n",
       " '0001pt',\n",
       " '0001we',\n",
       " '0001x',\n",
       " '0002',\n",
       " '000201bdaabb',\n",
       " '000201bdc8cb',\n",
       " '000201bdcbb8',\n",
       " '000201c265a3',\n",
       " '00024355',\n",
       " '000255000',\n",
       " '0002phone',\n",
       " '0003',\n",
       " '000301c634d3',\n",
       " '000301c6430e',\n",
       " '00033577',\n",
       " '0003qj',\n",
       " '0004',\n",
       " '00048z',\n",
       " '0004ek',\n",
       " '0004ti',\n",
       " '0005',\n",
       " '000501bdca45',\n",
       " '000501c62cfa',\n",
       " '000548',\n",
       " '0006',\n",
       " '0006ms',\n",
       " '0006pn',\n",
       " '0006z8',\n",
       " '0007',\n",
       " '00077u',\n",
       " '0007ka',\n",
       " '0008',\n",
       " '000801c59181',\n",
       " '0009',\n",
       " '000901c0e23e',\n",
       " '0009lcdrout',\n",
       " '000a',\n",
       " '000a01bdea63',\n",
       " '000antiprotons',\n",
       " '000audre',\n",
       " '000b01c66cb8',\n",
       " '000bachelor',\n",
       " '000barrels',\n",
       " '000br',\n",
       " '000c',\n",
       " '000c01bdcdc7',\n",
       " '000c01c6714b',\n",
       " '000company',\n",
       " '000dear',\n",
       " '000doctorate',\n",
       " '000e',\n",
       " '000e137038fe07f0ea1e00000e1370ad14f0a238060170380382783800fc7f18157f941b',\n",
       " '000equals',\n",
       " '000eur',\n",
       " '000f01bee9ca',\n",
       " '000f01c0fa97',\n",
       " '000hours',\n",
       " '000i',\n",
       " '000in',\n",
       " '000industry',\n",
       " '000k',\n",
       " '000live',\n",
       " '000m',\n",
       " '000master',\n",
       " '000mk',\n",
       " '000no',\n",
       " '000over',\n",
       " '000rpm',\n",
       " '000some',\n",
       " '000stipend',\n",
       " '000summary',\n",
       " '000t',\n",
       " '000this',\n",
       " '000uponcompletion',\n",
       " '000visitors',\n",
       " '000yes',\n",
       " '000you',\n",
       " '000контактные',\n",
       " '000アブノーマル1時間',\n",
       " '000元',\n",
       " '000元以內',\n",
       " '000円',\n",
       " '000円のみが必要となりますが',\n",
       " '000円不要',\n",
       " '000性感ノーマル',\n",
       " '001',\n",
       " '0010',\n",
       " '00100000',\n",
       " '00100001',\n",
       " '001001bee9ca',\n",
       " '00101380381e0700ea1fff5b13f8ea17e00010c7fca6ea11f8ea120cea1c07381803801210380001c0a214e0a4127012f0a200e013c01280ea4003148038200700ea1006ea0c1cea03f013227ea018',\n",
       " '0011',\n",
       " '001111111',\n",
       " '0012',\n",
       " '001201bee9d7',\n",
       " '001201beedd8',\n",
       " '00126',\n",
       " '0013',\n",
       " '0014',\n",
       " '001401bf04c9',\n",
       " '001501bde71a',\n",
       " '001532edt',\n",
       " '001601bde7b0',\n",
       " '001701bde82b',\n",
       " '0018',\n",
       " '001801bde88a',\n",
       " '001888',\n",
       " '0019',\n",
       " '00191',\n",
       " '001a',\n",
       " '001aa',\n",
       " '001d',\n",
       " '001e133000231370ea438014e01283ea8700a2380701c0120ea3381c0380a4eb0700a35bea0c3eea03ceea000ea25b1260eaf0381330485aea80c0ea4380003ec7fc141f7b9418',\n",
       " '001e1360002313e0ea4380eb81c01283ea8701a238070380120ea3381c0700a31408eb0e101218121ceb1e20ea0c263807c3c015157b941a',\n",
       " '001eb1ec',\n",
       " '001eboard',\n",
       " '001eeb60e00023ebe0f0384380e1eb81c000831470d887011330a23907038020120ea3391c070040a31580a2ec0100130f380c0b02380613843803e0f81c157b9420',\n",
       " '001f01c0faab',\n",
       " '001f01c275ca',\n",
       " '001fb512f8391e03c03800181418123038200780a200401410a2eb0f001280a200001400131ea45ba45ba45ba4485aa41203b5fc1d2277a123',\n",
       " '001fboard',\n",
       " '001fd',\n",
       " '001kp',\n",
       " '001mk',\n",
       " '002',\n",
       " '0020',\n",
       " '00203228888',\n",
       " '0020afec18ca',\n",
       " '0020j',\n",
       " '0021',\n",
       " '00212',\n",
       " '0022',\n",
       " '002249',\n",
       " '002289481249mail',\n",
       " '0022uf',\n",
       " '0023',\n",
       " '002321',\n",
       " '00233',\n",
       " '0024',\n",
       " '0025',\n",
       " '0025fax',\n",
       " '0026',\n",
       " '002601c66a38',\n",
       " '0027',\n",
       " '002712est',\n",
       " '0028',\n",
       " '002801c13bab',\n",
       " '0028ii',\n",
       " '0029',\n",
       " '002930_voxinfo',\n",
       " '0029817706609725333l434294481',\n",
       " '002983',\n",
       " '0029porta',\n",
       " '002_dragon004200943940content',\n",
       " '002_dragon008535651103',\n",
       " '002_dragon013699393919',\n",
       " '002_dragon019357534987content',\n",
       " '002_dragon020181421106',\n",
       " '002_dragon032685489904content',\n",
       " '002_dragon034150072259',\n",
       " '002_dragon034633567807content',\n",
       " '002_dragon039925383399content',\n",
       " '002_dragon040476364422',\n",
       " '002_dragon048889247829content',\n",
       " '002_dragon056675156800',\n",
       " '002_dragon058285243905content',\n",
       " '002_dragon060280103893content',\n",
       " '002_dragon073148149514',\n",
       " '002_dragon074457059520',\n",
       " '002_dragon077329414837',\n",
       " '002_dragon080566096389content',\n",
       " '002_dragon092734619076content',\n",
       " '002_dragon100455099132content',\n",
       " '002_dragon108076263577content',\n",
       " '002_dragon108468622097content',\n",
       " '002_dragon120569444328',\n",
       " '002_dragon122521392039content',\n",
       " '002_dragon128631707502content',\n",
       " '002_dragon133773915096content',\n",
       " '002_dragon136224228356content',\n",
       " '002_dragon138839954923',\n",
       " '002_dragon140844353194',\n",
       " '002_dragon142360745850content',\n",
       " '002_dragon143330654218',\n",
       " '002_dragon149449844292',\n",
       " '002_dragon161509917710',\n",
       " '002_dragon162756092795content',\n",
       " '002_dragon168204929497content',\n",
       " '002_dragon169002695074',\n",
       " '002_dragon169085030403content',\n",
       " '002_dragon176086318908',\n",
       " '002_dragon177944757813content',\n",
       " '002_dragon179326334746',\n",
       " '002_dragon183888777798content',\n",
       " '002_dragon183941553104content',\n",
       " '002_dragon185781585974',\n",
       " '002_dragon186514966961_',\n",
       " '002_dragon188257448684content',\n",
       " '002_dragon188333289331content',\n",
       " '002_dragon189316002559content',\n",
       " '002_dragon193530954717content',\n",
       " '002_dragon196072547742',\n",
       " '002_dragon198189501342content',\n",
       " '002_dragon203013389770content',\n",
       " '002_dragon204052897310',\n",
       " '002_dragon205793002835content',\n",
       " '002_dragon206018273441content',\n",
       " '002_dragon207785784570content',\n",
       " '002_dragon210159025107content',\n",
       " '002_dragon211481662238',\n",
       " '002_dragon212983034666content',\n",
       " '002_dragon213924637584content',\n",
       " '002_dragon214166912429',\n",
       " '002_dragon214895540320',\n",
       " '002_dragon215886918037',\n",
       " '002_dragon216410465126content',\n",
       " '002_dragon231888896784content',\n",
       " '002_dragon233134712957content',\n",
       " '002_dragon234879898522content',\n",
       " '002_dragon235764159952content',\n",
       " '002_dragon237516939735',\n",
       " '002_dragon239516577637content',\n",
       " '002_dragon240032945636content',\n",
       " '002_dragon248564804421content',\n",
       " '002_dragon249354945590content',\n",
       " '002_dragon249807569787content',\n",
       " '002_dragon254481303756',\n",
       " '002_dragon256918362398',\n",
       " '002_dragon262221859113',\n",
       " '002_dragon264396653478',\n",
       " '002_dragon264441716722content',\n",
       " '002_dragon265325440711content',\n",
       " '002_dragon266209308694content',\n",
       " '002_dragon269013230617content',\n",
       " '002_dragon270367826058content',\n",
       " '002_dragon273382864054content',\n",
       " '002_dragon273895548293',\n",
       " '002_dragon281660342386content',\n",
       " '002_dragon285173245356content',\n",
       " '002_dragon289924567963content',\n",
       " '002_dragon291265061908content',\n",
       " '002_dragon292505557095content',\n",
       " '002_dragon293119990835content',\n",
       " '002_dragon295843020376content',\n",
       " '002_dragon302510766348',\n",
       " '002_dragon302921738635',\n",
       " '002_dragon310127751282content',\n",
       " '002_dragon310651914794content',\n",
       " '002_dragon313149702908',\n",
       " '002_dragon317695925892content',\n",
       " '002_dragon318665289543content',\n",
       " '002_dragon319948883600',\n",
       " '002_dragon320946592690content',\n",
       " '002_dragon322915006407',\n",
       " '002_dragon324589698709content',\n",
       " '002_dragon327437312378content',\n",
       " '002_dragon327643673166content',\n",
       " '002_dragon330573254373content',\n",
       " '002_dragon333436883450content',\n",
       " '002_dragon336214030309content',\n",
       " '002_dragon340834821974',\n",
       " '002_dragon341612040241',\n",
       " '002_dragon343333554216',\n",
       " '002_dragon345724565924content',\n",
       " '002_dragon346394276285content',\n",
       " '002_dragon348016147037content',\n",
       " '002_dragon356616615600content',\n",
       " '002_dragon359805902139content',\n",
       " '002_dragon361767389765',\n",
       " '002_dragon366284922033',\n",
       " '002_dragon370830372714',\n",
       " '002_dragon377070002978content',\n",
       " '002_dragon377441852287',\n",
       " '002_dragon384660614980content',\n",
       " '002_dragon389780210192content',\n",
       " '002_dragon390632298472content',\n",
       " '002_dragon391848222368content',\n",
       " '002_dragon399477789492content',\n",
       " '002_dragon402079065150',\n",
       " '002_dragon402740244099content',\n",
       " '002_dragon409823729458content',\n",
       " '002_dragon410509063251content',\n",
       " '002_dragon411110209560content',\n",
       " '002_dragon413436947052content',\n",
       " '002_dragon415805250710content',\n",
       " '002_dragon416123410162content',\n",
       " '002_dragon425323668785content',\n",
       " '002_dragon431429810021content',\n",
       " '002_dragon431676018905content',\n",
       " '002_dragon432852498332content',\n",
       " '002_dragon437917652885content',\n",
       " '002_dragon440034119332',\n",
       " '002_dragon441674338630',\n",
       " '002_dragon442592498835',\n",
       " '002_dragon443472164152content',\n",
       " '002_dragon443689150123content',\n",
       " '002_dragon444004361912content',\n",
       " '002_dragon448288168555content',\n",
       " '002_dragon451319953791',\n",
       " '002_dragon451657700235content',\n",
       " '002_dragon456176210945content',\n",
       " '002_dragon468266803279content',\n",
       " '002_dragon470466639645',\n",
       " '002_dragon473323566965',\n",
       " '002_dragon476540816282content',\n",
       " '002_dragon477399743496content',\n",
       " '002_dragon479331544790content',\n",
       " '002_dragon483579780476content',\n",
       " '002_dragon484358097899content',\n",
       " '002_dragon488902243432',\n",
       " '002_dragon491393046235',\n",
       " '002_dragon495877656850content',\n",
       " '002_dragon504217449345',\n",
       " '002_dragon505110412875',\n",
       " '002_dragon505932322972',\n",
       " '002_dragon506805364816content',\n",
       " '002_dragon508712711421content',\n",
       " '002_dragon512122577234',\n",
       " '002_dragon513692340014content',\n",
       " '002_dragon514676478309content',\n",
       " '002_dragon515128794190',\n",
       " '002_dragon516011979524content',\n",
       " '002_dragon516666948361content',\n",
       " '002_dragon518255923908content',\n",
       " '002_dragon519557785805',\n",
       " '002_dragon520683972230content',\n",
       " '002_dragon522040799568',\n",
       " '002_dragon527791339896content',\n",
       " '002_dragon530821623860content',\n",
       " '002_dragon533304058117_',\n",
       " '002_dragon533835082890content',\n",
       " '002_dragon535670459181content',\n",
       " '002_dragon536989065088content',\n",
       " '002_dragon538638107395content',\n",
       " '002_dragon540629808243content',\n",
       " '002_dragon542105054566content',\n",
       " '002_dragon542522505882content',\n",
       " '002_dragon544018013072content',\n",
       " '002_dragon546536074428content',\n",
       " '002_dragon547081415263content',\n",
       " '002_dragon547831489158',\n",
       " '002_dragon554816776882content',\n",
       " '002_dragon557516700063content',\n",
       " '002_dragon558995758314',\n",
       " '002_dragon560194215614content',\n",
       " '002_dragon561824435930content',\n",
       " '002_dragon563227845761',\n",
       " '002_dragon564322207242content',\n",
       " '002_dragon571434638457',\n",
       " '002_dragon574371893608content',\n",
       " '002_dragon575169100404_',\n",
       " '002_dragon575585758776content',\n",
       " '002_dragon577596397905content',\n",
       " '002_dragon583411697069content',\n",
       " '002_dragon584915480615',\n",
       " '002_dragon585001720044content',\n",
       " '002_dragon585387820253',\n",
       " '002_dragon586232798130content',\n",
       " '002_dragon591660557037content',\n",
       " '002_dragon596828381337content',\n",
       " '002_dragon597439856990',\n",
       " '002_dragon599296306728',\n",
       " '002_dragon610136592431content',\n",
       " '002_dragon610953810273content',\n",
       " '002_dragon619468299972content',\n",
       " '002_dragon623245546434',\n",
       " '002_dragon623495405341content',\n",
       " '002_dragon625493329806content',\n",
       " '002_dragon634337155732content',\n",
       " '002_dragon636962270343content',\n",
       " '002_dragon643501113307',\n",
       " '002_dragon645239832728',\n",
       " '002_dragon645469919759content',\n",
       " '002_dragon647819242747content',\n",
       " '002_dragon648837860654content',\n",
       " '002_dragon660060898871content',\n",
       " '002_dragon660123564464content',\n",
       " '002_dragon664173122785content',\n",
       " '002_dragon669679313152content',\n",
       " '002_dragon671339860625content',\n",
       " '002_dragon671413180375',\n",
       " '002_dragon682176656828',\n",
       " '002_dragon682242077477',\n",
       " '002_dragon683701003467',\n",
       " '002_dragon683848968845',\n",
       " '002_dragon684485696525content',\n",
       " '002_dragon685743176115content',\n",
       " '002_dragon700393232030content',\n",
       " '002_dragon702086349026',\n",
       " '002_dragon706880655832content',\n",
       " '002_dragon710680206378',\n",
       " '002_dragon714483479317content',\n",
       " '002_dragon715506809858content',\n",
       " '002_dragon721447944431content',\n",
       " '002_dragon721496209399content',\n",
       " '002_dragon735922421923content',\n",
       " '002_dragon744366455165',\n",
       " '002_dragon745440808393content',\n",
       " '002_dragon745846869871content',\n",
       " '002_dragon749046174059',\n",
       " '002_dragon749135313276content',\n",
       " '002_dragon749616001928content',\n",
       " '002_dragon749775980445',\n",
       " '002_dragon752042517009content',\n",
       " '002_dragon752940174982content',\n",
       " '002_dragon756883035274content',\n",
       " '002_dragon758472607762',\n",
       " '002_dragon760169235045content',\n",
       " '002_dragon762646400558content',\n",
       " '002_dragon763409779758',\n",
       " '002_dragon773027103006',\n",
       " '002_dragon777504927530',\n",
       " '002_dragon779053823085content',\n",
       " '002_dragon779723947235content',\n",
       " '002_dragon785824725207',\n",
       " '002_dragon785883807422content',\n",
       " '002_dragon787036265046',\n",
       " '002_dragon788617422663',\n",
       " '002_dragon789549662168content',\n",
       " '002_dragon790560539053',\n",
       " '002_dragon790568223600',\n",
       " '002_dragon796954387895content',\n",
       " '002_dragon799105077372',\n",
       " '002_dragon803951708982content',\n",
       " '002_dragon805058253897content',\n",
       " '002_dragon806793363072',\n",
       " '002_dragon809654126877_',\n",
       " '002_dragon809864011866content',\n",
       " '002_dragon813633483461content',\n",
       " '002_dragon813978104655',\n",
       " '002_dragon820046601046content',\n",
       " '002_dragon821031089314content',\n",
       " '002_dragon833788956448_',\n",
       " '002_dragon835344230368content',\n",
       " '002_dragon835873675296content',\n",
       " '002_dragon836071345290',\n",
       " '002_dragon837387913413content',\n",
       " '002_dragon838552296986',\n",
       " '002_dragon844804994340content',\n",
       " '002_dragon852494520224',\n",
       " '002_dragon853396716332content',\n",
       " '002_dragon859035731542',\n",
       " '002_dragon866142856789',\n",
       " '002_dragon871663965498',\n",
       " '002_dragon872235195865content',\n",
       " '002_dragon875584409480content',\n",
       " '002_dragon882261761834',\n",
       " '002_dragon882895304044content',\n",
       " '002_dragon887388321534content',\n",
       " '002_dragon890168734255',\n",
       " '002_dragon890932882408content',\n",
       " '002_dragon898049280100content',\n",
       " '002_dragon908062144026content',\n",
       " '002_dragon912634163458content',\n",
       " '002_dragon917066359101',\n",
       " '002_dragon943687789736',\n",
       " '002_dragon953322195972content',\n",
       " '002_dragon955500430856content',\n",
       " '002_dragon956476021852content',\n",
       " '002_dragon959715935339content',\n",
       " '002_dragon966803059116content',\n",
       " '002_dragon975760983408content',\n",
       " '002_dragon975935048487content',\n",
       " '002_dragon980145547667content',\n",
       " '002_dragon981554492198content',\n",
       " '002_dragon984547041819',\n",
       " '002_dragon986057447477content',\n",
       " '002_dragon993740048225content',\n",
       " '002_dragon998760730906',\n",
       " '002_dragon998895130427content',\n",
       " '002a01c2724f',\n",
       " '002br',\n",
       " '002d01c26659',\n",
       " '002d01c66d57',\n",
       " '002d16e0',\n",
       " '002d16e0content',\n",
       " '002data',\n",
       " '002e62',\n",
       " '002f40f4',\n",
       " '002hn',\n",
       " '002mk',\n",
       " '002time',\n",
       " '003',\n",
       " '0030',\n",
       " '003001bee908',\n",
       " '00301320383e01e0383fffc0148014005b13f8ea33c00030c7fca4ea31fcea37ff383e0fc0383807e0ea3003000013f0a214f8a21238127c12fea200fc13f0a2387007e0003013c0383c1f80380fff00ea03f815207d9f1c',\n",
       " '0031',\n",
       " '00316',\n",
       " '0031630926532',\n",
       " '0031847131601',\n",
       " '003201c67c38',\n",
       " '0033',\n",
       " '003301beebdc',\n",
       " '003366',\n",
       " '003399',\n",
       " '0034',\n",
       " '0034pulse_default',\n",
       " '0034tcnt',\n",
       " '0035',\n",
       " '003501beebdf',\n",
       " '0038',\n",
       " '0039',\n",
       " '003901beebdf',\n",
       " '003901c67c7a',\n",
       " '003_dragon056507828553_',\n",
       " '003_dragon340468286956_',\n",
       " '003_dragon346143145919_',\n",
       " '003_dragon426402787230_',\n",
       " '003_dragon744672031743_',\n",
       " '003br',\n",
       " '003fax',\n",
       " '003nl',\n",
       " '003pt',\n",
       " '004',\n",
       " '0040',\n",
       " '0040095e21234',\n",
       " '004093',\n",
       " '0040b0b1',\n",
       " '0040b0b10069f628',\n",
       " '0040b530',\n",
       " '0041',\n",
       " '004101c67c3c',\n",
       " '0042',\n",
       " '004201beebf9',\n",
       " '0043',\n",
       " '0043c77a',\n",
       " '0043fec0',\n",
       " '0044',\n",
       " '004499',\n",
       " '0044eb9c',\n",
       " '0044f6dc',\n",
       " '0045subroutine_servo_a5_init',\n",
       " '00468078',\n",
       " '0046937f',\n",
       " '00469d74',\n",
       " '00469d76',\n",
       " '0048',\n",
       " '0049',\n",
       " '0049servo_a5_pulse',\n",
       " '004c',\n",
       " '004nl',\n",
       " '005',\n",
       " '005004',\n",
       " '0050servo_a5_int',\n",
       " '005135',\n",
       " '0052servo_bit',\n",
       " '0053',\n",
       " '005301beedb7',\n",
       " '0054',\n",
       " '0058',\n",
       " '0059',\n",
       " '0059variable_servo_a5_pulse',\n",
       " '005a',\n",
       " '005amicrosoft',\n",
       " '005aupdate',\n",
       " '005c',\n",
       " '005d01bf6f13',\n",
       " '005hn',\n",
       " '005la',\n",
       " '005mk',\n",
       " '006',\n",
       " '0060',\n",
       " '00632d93',\n",
       " '0063825485257156_',\n",
       " '0063825485257156_content',\n",
       " '0063825785257156_',\n",
       " '0063825785257156_content',\n",
       " '00638260',\n",
       " '0063servo_enable',\n",
       " '0064',\n",
       " '0064setup_gap',\n",
       " '0065',\n",
       " '00664e75',\n",
       " '00667',\n",
       " '00667280',\n",
       " '0066993785257156_',\n",
       " '0066993785257156_content',\n",
       " '0066993a85257156_',\n",
       " '0066993a85257156_content',\n",
       " '00669945',\n",
       " '006765d8',\n",
       " '0067tctl1',\n",
       " '0068',\n",
       " '0068a474',\n",
       " '0068a574',\n",
       " '0068da84',\n",
       " '0068uf',\n",
       " '0068uff',\n",
       " '0069',\n",
       " '0069d154',\n",
       " '0069f5b8',\n",
       " '0069f5e0',\n",
       " '0069f5e0ecx',\n",
       " '0069f628',\n",
       " '0069fa36',\n",
       " '0069fcf8',\n",
       " '006a',\n",
       " '006b57d8',\n",
       " '006bb7f8',\n",
       " '006c2ce4',\n",
       " '006c67cc',\n",
       " '006e',\n",
       " '006hn',\n",
       " '006hz',\n",
       " '006karnatakaindiaph',\n",
       " '006la',\n",
       " '006mk',\n",
       " '006nl',\n",
       " '006ov',\n",
       " '006performing',\n",
       " '007',\n",
       " '0070',\n",
       " '007083ac',\n",
       " '0071',\n",
       " '00717',\n",
       " '0072',\n",
       " '0072for',\n",
       " '0073',\n",
       " '0074',\n",
       " '0075',\n",
       " '0076194298',\n",
       " '00762',\n",
       " '0077',\n",
       " '0077author',\n",
       " '0078',\n",
       " '0078title',\n",
       " '00794d20',\n",
       " '00795ce0',\n",
       " '00798ab0',\n",
       " '007a4e40',\n",
       " '007b0100',\n",
       " '007b5860',\n",
       " '007br',\n",
       " '007cb350',\n",
       " '007fb512f839780780780060141800401408a300c0140c00801404a400001400b3a3497e3801fffe1e227ea123',\n",
       " '007fb61280a2397e03f80f00781407007014030060140100e015c0a200c01400a400001500b3a248b512f0a222227ea127',\n",
       " '007fb8fca39039c00ff801d87e00ec003f007c82007882a200708200f01780a3481603a5c792c7fcb3aa017fb6fca331307daf38',\n",
       " '007fd',\n",
       " '007parkerbros',\n",
       " '007you',\n",
       " '008',\n",
       " '0080',\n",
       " '00800',\n",
       " '008000',\n",
       " '0081',\n",
       " '0082',\n",
       " '0082toc3',\n",
       " '0083903358',\n",
       " '0084',\n",
       " '008482',\n",
       " '0085',\n",
       " '0085weekly',\n",
       " '0087',\n",
       " '008723514',\n",
       " '0087411652337',\n",
       " '0088cforc',\n",
       " '0088office',\n",
       " '0089',\n",
       " '0089tmsk1',\n",
       " '008br',\n",
       " '008ov',\n",
       " '008scan1',\n",
       " '008scan1testa',\n",
       " '009',\n",
       " '0090',\n",
       " '00901a',\n",
       " '0091',\n",
       " '0092',\n",
       " '0093',\n",
       " '0093according',\n",
       " '0093bac',\n",
       " '0093calls',\n",
       " '0093contact',\n",
       " '0093no',\n",
       " '0093subroutine_initialize_module',\n",
       " '0095setup_pulse',\n",
       " '0096',\n",
       " '0097612',\n",
       " '0097616095',\n",
       " '0098',\n",
       " '0098d3',\n",
       " '0099',\n",
       " '009901c29c95',\n",
       " '0099ff',\n",
       " '009a01c29c9a',\n",
       " '009baba3',\n",
       " '009br',\n",
       " '009c01bee96b',\n",
       " '009c0380',\n",
       " '009mk',\n",
       " '00a301bee7d1',\n",
       " '00aa00342820',\n",
       " '00aa01c59196',\n",
       " '00am',\n",
       " '00analog',\n",
       " '00assistant',\n",
       " '00b14878',\n",
       " '00c',\n",
       " '00c04fd7081f',\n",
       " '00c04fd97575',\n",
       " '00can',\n",
       " '00cf01bee7d2',\n",
       " '00customers',\n",
       " '00dc',\n",
       " '00ddvtnaxl7vqmz',\n",
       " '00e03u',\n",
       " '00e4',\n",
       " '00est',\n",
       " '00euro',\n",
       " '00faabobqaatwuaafafaabrbqaauguaafmfaabubqaavquaafyfaabxbqaawauaafkfaababqaawwuaafwfaabdbqaaxguaaf8faabgbqaayquaagifaabjbqaazauaagufaabmbqaazwuaaggfaabpbqaaaguaagsfaabsbqaabquaag4faabvbqaacauaahefaabybqaacwuaahqfaab1bqaadguaahcfaab4bqaaequaahofaab7bqaafauaah0faab',\n",
       " '00ff',\n",
       " '00ffff',\n",
       " '00for',\n",
       " '00golden',\n",
       " '00h',\n",
       " '00i',\n",
       " '00in',\n",
       " '00jan',\n",
       " '00ms',\n",
       " '00msgraphic',\n",
       " '00multiple',\n",
       " '00numbers',\n",
       " '00p',\n",
       " '00pm',\n",
       " '00pmemu',\n",
       " '00pmregistration',\n",
       " '00pmthe',\n",
       " '00pmweir',\n",
       " '00pmwhile',\n",
       " '00pnear',\n",
       " '00r',\n",
       " '00readme',\n",
       " '00secondary',\n",
       " '00shipping',\n",
       " '00subject',\n",
       " '00the',\n",
       " '00tim',\n",
       " '00time',\n",
       " '00total',\n",
       " '00u',\n",
       " '00usd',\n",
       " '00use',\n",
       " '00v',\n",
       " '00vga',\n",
       " '00what',\n",
       " '00which',\n",
       " '00x0c',\n",
       " '00x0f',\n",
       " '00you',\n",
       " '00z',\n",
       " '00以後',\n",
       " '00您在做什麼',\n",
       " '01',\n",
       " '010',\n",
       " '0100',\n",
       " '01000000',\n",
       " '0100007f',\n",
       " '01002413',\n",
       " '0100a8c0',\n",
       " '0100after',\n",
       " '0100d3',\n",
       " '0100from',\n",
       " '0100hello',\n",
       " '0100hi',\n",
       " '0100jonathan',\n",
       " '0100lee',\n",
       " '0100message',\n",
       " '0100mime',\n",
       " '0100ok',\n",
       " '0100on',\n",
       " '0100organization',\n",
       " '0100reply',\n",
       " '0100subject',\n",
       " '0100to',\n",
       " '0101',\n",
       " '0101e',\n",
       " '0102',\n",
       " '0103',\n",
       " '010307',\n",
       " '0105',\n",
       " '0106',\n",
       " '01062',\n",
       " '01063',\n",
       " '01063voice',\n",
       " '0106no',\n",
       " '0107',\n",
       " '010703',\n",
       " '010718',\n",
       " '0108',\n",
       " '010918',\n",
       " '0109toc3int',\n",
       " '010a',\n",
       " '010amicrosoft',\n",
       " '010kp',\n",
       " '010nl',\n",
       " '010ov',\n",
       " '011',\n",
       " '0110',\n",
       " '0111',\n",
       " '0112pactl',\n",
       " '0112servo_port',\n",
       " '01132',\n",
       " '0113tflg1',\n",
       " '0114',\n",
       " '0114f',\n",
       " '01155',\n",
       " '0115518009',\n",
       " '011557est',\n",
       " '0115la',\n",
       " '0115servo_disable',\n",
       " '0115tel',\n",
       " '0116349',\n",
       " '0116349proposal',\n",
       " '0117',\n",
       " '01184',\n",
       " '011a',\n",
       " '011aapple',\n",
       " '011commercial',\n",
       " '011fd',\n",
       " '011nl',\n",
       " '011ov',\n",
       " '012',\n",
       " '0120',\n",
       " '012002',\n",
       " '01223',\n",
       " '0123',\n",
       " '012437',\n",
       " '0125',\n",
       " '0126phone',\n",
       " '0128',\n",
       " '012amultiple',\n",
       " '012br',\n",
       " '012fd',\n",
       " '012mk',\n",
       " '013',\n",
       " '0130',\n",
       " '01309',\n",
       " '01311',\n",
       " '0133',\n",
       " '0133info',\n",
       " '0133net',\n",
       " '0136716296',\n",
       " '0138',\n",
       " '01392',\n",
       " '0139648437',\n",
       " '013br',\n",
       " '013fd',\n",
       " '013hn',\n",
       " '013kp',\n",
       " '013mk',\n",
       " '014',\n",
       " '01406',\n",
       " '01409',\n",
       " ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the fitted vocabulary\n",
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform training data into a 'document-term matrix'\n",
    "X_train_dtm = vect.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# equivalently: combine fit and transform into a single step\n",
    "X_train_dtm = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<23230x161925 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2305787 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the document-term matrix\n",
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7744x161925 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 744528 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 5: Building and evaluating a model\n",
    "\n",
    "We will use [multinomial Naive Bayes](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html):\n",
    "\n",
    "> The multinomial Naive Bayes classifier is suitable for classification with **discrete features** (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# import and instantiate a Multinomial Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.9 ms, sys: 10.9 ms, total: 56.9 ms\n",
      "Wall time: 57 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using X_train_dtm (timing it with an IPython \"magic command\")\n",
    "%time nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98476239669421484"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2967,    7],\n",
       "       [ 111, 4659]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98      2974\n",
      "          1       1.00      0.98      0.99      4770\n",
      "\n",
      "avg / total       0.99      0.98      0.98      7744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00000000e+00,   1.00000000e+00,   1.73677105e-31, ...,\n",
       "         1.00000000e+00,   1.00000000e+00,   7.77424439e-01])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predicted probabilities for X_test_dtm (poorly calibrated)\n",
    "y_pred_prob = nb.predict_proba(X_test_dtm)[:, 1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99670526815912608"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate AUC\n",
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 7: Examining a model for further insight\n",
    "\n",
    "We will examine the our **trained Naive Bayes model** to calculate the approximate **\"spamminess\" of each token**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161925"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the vocabulary of X_train\n",
    "X_train_tokens = vect.get_feature_names()\n",
    "len(X_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '0000', '000000', '0000000', '00000000', '000000000', '00000000000000', '000000000000000000000000000000049999999999999e9', '0000000000000000000000000000000500000000000000e9', '0000000000000016666l', '0000000000000017d', '00000000000000e', '000000000000received', '000000000001received', '0000000001d0', '0000000001l0', '0000000010000000004l0', '0000000016', '000000001d0', '00000000message', '00000000x', '00000001', '00000001content', '00000001irdecode', '00000004', '00000010', '00000010pwm', '00000011', '00000049', '0000005', '0000006hz', '000000eb', '000001', '00000100', '00000100shaftencoder', '000001bdaaa0', '000001bdb744', '000001bdcaf3', '000001c642d0', '000001c64310', '000001c64585', '000001c64615', '000001c64641', '000001c6465f', '000001c6468e', '0000020', '0000040', '0000040b', '0000040c']\n"
     ]
    }
   ],
   "source": [
    "# examine the first 50 tokens\n",
    "print(X_train_tokens[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['３ｄバーチャルｓｅｘメーカー', '４名紹介http', '４月度新規メンバー様応援企画パーティー開催予定', '４月２３日', '５月までのようなので興味のある方はお早めに', '５月中週末３人か４人ぐらいで', '５００円分のポイントが完全無料で自動追加されます', '６名のみとなります', 'ａ型', 'ａ美様現在未亡人でいらっしゃいます', 'ｂ９６', 'ｆカップ', 'ｇａｌ誌多数掲載', 'ｇｏｏｄ', 'ｇｒａｎｄｅｅ', 'ｇｒａｎｄｅｅの理念やシステムのご紹介', 'ｇｗこそ出会いのチャンスhttp', 'ｇｗです', 'ｇｗはこういう女の子と過ごしたいっす', 'ｇｗ特典あり', 'ｈなこと大好きな人ばかり', 'ｈな女の子が多いので', 'ｈな欲望や願望を胸に秘め', 'ｈにそんなに興味なかったのと少し怖いのもあるため', 'ｈのお相手しただけで', 'ｈゲームメーカーの決定版', 'ｈ度', 'ｈ目的の出会いも簡単です', 'ｈ８６', 'ｋ村', 'ｍ子様セーリングクルーザーをお持ちで', 'ｍ字開脚オナニーを机の下から盗撮', 'ｍａｉｌでのサポートは２４時間対応です', 'ｎ藤', 'ｏｌ', 'ｐｃ', 'ｐｃから簡単プロフィール作成', 'ｓクラス専門店', 'ｓ子様秘密が条件で', 'ｓｅｘを求めている', 'ｓｅｘを求めているのです', 'ｓｍ', 'ｔ165', 'ｔバックは', 'ｔバックはいていたらおならが左右に分散するのでなんか変な感じですけどね', 'ｔバックを購入しました', 'ｔ島', 'ｔ谷', 'ｗ６２', 'ｙ里様お互いがくつろげるような']\n"
     ]
    }
   ],
   "source": [
    "# examine the last 50 tokens\n",
    "print(X_train_tokens[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.00900000e+03,   3.90000000e+02,   3.76000000e+02, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  3.63700000e+03,   5.30400000e+03,   0.00000000e+00, ...,\n",
       "          2.00000000e+00,   1.00000000e+00,   2.00000000e+00]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes counts the number of times each token appears in each class\n",
    "nb.feature_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 161925)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows represent classes, columns represent tokens\n",
    "nb.feature_count_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2009.,   390.,   376., ...,     0.,     0.,     0.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of times each token appears across all HAM messages\n",
    "ham_token_count = nb.feature_count_[0, :]\n",
    "ham_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.63700000e+03,   5.30400000e+03,   0.00000000e+00, ...,\n",
       "         2.00000000e+00,   1.00000000e+00,   2.00000000e+00])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of times each token appears across all SPAM messages\n",
    "spam_token_count = nb.feature_count_[1, :]\n",
    "spam_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>2009.0</td>\n",
       "      <td>3637.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>390.0</td>\n",
       "      <td>5304.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000</th>\n",
       "      <td>376.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000</th>\n",
       "      <td>50.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000000</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ham    spam\n",
       "token                  \n",
       "00       2009.0  3637.0\n",
       "000       390.0  5304.0\n",
       "0000      376.0     0.0\n",
       "000000     50.0    62.0\n",
       "0000000     1.0     0.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DataFrame of tokens with their separate ham and spam counts\n",
    "tokens = pd.DataFrame({'token':X_train_tokens, 'ham':ham_token_count, 'spam':spam_token_count}).set_index('token')\n",
    "tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bench</th>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bitmapsand</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gosses</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tome</th>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ham  spam\n",
       "token                 \n",
       "bench       14.0   7.0\n",
       "bitmapsand   1.0   0.0\n",
       "gosses       2.0   0.0\n",
       "tome         4.0   9.0\n",
       "1388         3.0   0.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine 5 random DataFrame rows\n",
    "tokens.sample(5, random_state=427)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8720.,  14510.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes counts the number of observations in each class\n",
    "nb.class_count_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Before we can calculate the \"spamminess\" of each token, we need to avoid **dividing by zero** and account for the **class imbalance**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bench</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bitmapsand</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gosses</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tome</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ham  spam\n",
       "token                 \n",
       "bench       15.0   8.0\n",
       "bitmapsand   2.0   1.0\n",
       "gosses       3.0   1.0\n",
       "tome         5.0  10.0\n",
       "1388         4.0   1.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add 1 to ham and spam counts to avoid dividing by 0\n",
    "tokens['ham'] = tokens.ham + 1\n",
    "tokens['spam'] = tokens.spam + 1\n",
    "tokens.sample(5, random_state=427)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bench</th>\n",
       "      <td>0.001720</td>\n",
       "      <td>0.000551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bitmapsand</th>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gosses</th>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tome</th>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.000689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ham      spam\n",
       "token                         \n",
       "bench       0.001720  0.000551\n",
       "bitmapsand  0.000229  0.000069\n",
       "gosses      0.000344  0.000069\n",
       "tome        0.000573  0.000689\n",
       "1388        0.000459  0.000069"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the ham and spam counts into frequencies\n",
    "tokens['ham'] = tokens.ham / nb.class_count_[0]\n",
    "tokens['spam'] = tokens.spam / nb.class_count_[1]\n",
    "tokens.sample(5, random_state=427)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "      <th>spam_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bench</th>\n",
       "      <td>0.001720</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.320515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bitmapsand</th>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.300482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gosses</th>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.200322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tome</th>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>1.201930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.150241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ham      spam  spam_ratio\n",
       "token                                     \n",
       "bench       0.001720  0.000551    0.320515\n",
       "bitmapsand  0.000229  0.000069    0.300482\n",
       "gosses      0.000344  0.000069    0.200322\n",
       "tome        0.000573  0.000689    1.201930\n",
       "1388        0.000459  0.000069    0.150241"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the ratio of spam-to-ham for each token\n",
    "tokens['spam_ratio'] = tokens.spam / tokens.ham\n",
    "tokens.sample(5, random_state=427)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "      <th>spam_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>product_table</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.640662</td>\n",
       "      <td>5586.569263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15px</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.201447</td>\n",
       "      <td>1756.620262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0px</th>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.726465</td>\n",
       "      <td>1583.692626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proms</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.160510</td>\n",
       "      <td>1399.647140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>professionaladobe</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.160510</td>\n",
       "      <td>1399.647140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hereopt</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.125844</td>\n",
       "      <td>1097.361819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.122605</td>\n",
       "      <td>1069.116471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95more</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.120400</td>\n",
       "      <td>1049.885596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compacted_description</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.120400</td>\n",
       "      <td>1049.885596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewsretail</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.120400</td>\n",
       "      <td>1049.885596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00you</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.120400</td>\n",
       "      <td>1049.885596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoodia</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.109097</td>\n",
       "      <td>951.327360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs2</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.104893</td>\n",
       "      <td>914.668504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cantex</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.102481</td>\n",
       "      <td>893.634735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13px</th>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.201861</td>\n",
       "      <td>880.113025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>無料</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.098691</td>\n",
       "      <td>860.581668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weightzipping</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.081668</td>\n",
       "      <td>712.143349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bestsellers</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.081392</td>\n",
       "      <td>709.739490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sp_cont</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.080289</td>\n",
       "      <td>700.124052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5adobe</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.080289</td>\n",
       "      <td>700.124052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greylink</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.080289</td>\n",
       "      <td>700.124052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compacted_price</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.080289</td>\n",
       "      <td>700.124052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compacted_image</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.080289</td>\n",
       "      <td>700.124052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proadobe</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.080289</td>\n",
       "      <td>700.124052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00c</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.080289</td>\n",
       "      <td>700.124052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collectionadobe</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.080289</td>\n",
       "      <td>700.124052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rolex</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.058580</td>\n",
       "      <td>510.820124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discreet</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.058442</td>\n",
       "      <td>509.618194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bz</th>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.116678</td>\n",
       "      <td>508.716747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>herewant</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.055686</td>\n",
       "      <td>485.579600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fred</th>\n",
       "      <td>0.060894</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.001132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voltage</th>\n",
       "      <td>0.061124</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.001128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timedx</th>\n",
       "      <td>0.062729</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.001099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computing</th>\n",
       "      <td>0.063073</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.001093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analog</th>\n",
       "      <td>0.067890</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.001015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8babaaaaambg8afgd</th>\n",
       "      <td>0.068693</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.001003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weaeaaaacygdwawap</th>\n",
       "      <td>0.069037</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ir</th>\n",
       "      <td>0.069495</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>servo</th>\n",
       "      <td>0.070872</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sonar</th>\n",
       "      <td>0.071330</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starship</th>\n",
       "      <td>0.072706</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aqaqaaaajgypabya</th>\n",
       "      <td>0.075917</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgp</th>\n",
       "      <td>0.076720</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nil</th>\n",
       "      <td>0.231193</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sep</th>\n",
       "      <td>0.081307</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sensor</th>\n",
       "      <td>0.082339</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>routing</th>\n",
       "      <td>0.083830</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thu</th>\n",
       "      <td>0.087844</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>motors</th>\n",
       "      <td>0.095298</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linux</th>\n",
       "      <td>0.097592</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>libimlib</th>\n",
       "      <td>0.099197</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robot</th>\n",
       "      <td>0.113876</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>output</th>\n",
       "      <td>0.116628</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ribbon</th>\n",
       "      <td>0.121674</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>port</th>\n",
       "      <td>0.147248</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nodes</th>\n",
       "      <td>0.163532</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>node</th>\n",
       "      <td>0.166514</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>handy</th>\n",
       "      <td>0.167317</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cert</th>\n",
       "      <td>0.192775</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hb</th>\n",
       "      <td>0.193693</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161925 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            ham      spam   spam_ratio\n",
       "token                                                 \n",
       "product_table          0.000115  0.640662  5586.569263\n",
       "15px                   0.000115  0.201447  1756.620262\n",
       "0px                    0.000459  0.726465  1583.692626\n",
       "proms                  0.000115  0.160510  1399.647140\n",
       "professionaladobe      0.000115  0.160510  1399.647140\n",
       "hereopt                0.000115  0.125844  1097.361819\n",
       "fff                    0.000115  0.122605  1069.116471\n",
       "95more                 0.000115  0.120400  1049.885596\n",
       "compacted_description  0.000115  0.120400  1049.885596\n",
       "reviewsretail          0.000115  0.120400  1049.885596\n",
       "00you                  0.000115  0.120400  1049.885596\n",
       "hoodia                 0.000115  0.109097   951.327360\n",
       "cs2                    0.000115  0.104893   914.668504\n",
       "cantex                 0.000115  0.102481   893.634735\n",
       "13px                   0.000229  0.201861   880.113025\n",
       "無料                     0.000115  0.098691   860.581668\n",
       "weightzipping          0.000115  0.081668   712.143349\n",
       "bestsellers            0.000115  0.081392   709.739490\n",
       "sp_cont                0.000115  0.080289   700.124052\n",
       "5adobe                 0.000115  0.080289   700.124052\n",
       "greylink               0.000115  0.080289   700.124052\n",
       "compacted_price        0.000115  0.080289   700.124052\n",
       "compacted_image        0.000115  0.080289   700.124052\n",
       "proadobe               0.000115  0.080289   700.124052\n",
       "00c                    0.000115  0.080289   700.124052\n",
       "collectionadobe        0.000115  0.080289   700.124052\n",
       "rolex                  0.000115  0.058580   510.820124\n",
       "discreet               0.000115  0.058442   509.618194\n",
       "bz                     0.000229  0.116678   508.716747\n",
       "herewant               0.000115  0.055686   485.579600\n",
       "...                         ...       ...          ...\n",
       "fred                   0.060894  0.000069     0.001132\n",
       "voltage                0.061124  0.000069     0.001128\n",
       "timedx                 0.062729  0.000069     0.001099\n",
       "computing              0.063073  0.000069     0.001093\n",
       "analog                 0.067890  0.000069     0.001015\n",
       "8babaaaaambg8afgd      0.068693  0.000069     0.001003\n",
       "weaeaaaacygdwawap      0.069037  0.000069     0.000998\n",
       "ir                     0.069495  0.000069     0.000992\n",
       "servo                  0.070872  0.000069     0.000972\n",
       "sonar                  0.071330  0.000069     0.000966\n",
       "starship               0.072706  0.000069     0.000948\n",
       "aqaqaaaajgypabya       0.075917  0.000069     0.000908\n",
       "pgp                    0.076720  0.000069     0.000898\n",
       "nil                    0.231193  0.000207     0.000894\n",
       "sep                    0.081307  0.000069     0.000848\n",
       "sensor                 0.082339  0.000069     0.000837\n",
       "routing                0.083830  0.000069     0.000822\n",
       "thu                    0.087844  0.000069     0.000785\n",
       "motors                 0.095298  0.000069     0.000723\n",
       "linux                  0.097592  0.000069     0.000706\n",
       "libimlib               0.099197  0.000069     0.000695\n",
       "robot                  0.113876  0.000069     0.000605\n",
       "output                 0.116628  0.000069     0.000591\n",
       "ribbon                 0.121674  0.000069     0.000566\n",
       "port                   0.147248  0.000069     0.000468\n",
       "nodes                  0.163532  0.000069     0.000421\n",
       "node                   0.166514  0.000069     0.000414\n",
       "handy                  0.167317  0.000069     0.000412\n",
       "cert                   0.192775  0.000069     0.000358\n",
       "hb                     0.193693  0.000069     0.000356\n",
       "\n",
       "[161925 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the DataFrame sorted by spam_ratio\n",
    "# note: use sort() instead of sort_values() for pandas 0.16.2 and earlier\n",
    "tokens.sort_values('spam_ratio', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.449971806277802"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up the spam_ratio for a given token\n",
    "tokens.loc['adobe', 'spam_ratio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 9: Tuning the vectorizer (Challenge)\n",
    "\n",
    "Thus far, we have been using the default parameters of [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show default parameters for CountVectorizer\n",
    "vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "However, the vectorizer is worth tuning, just like a model is worth tuning! Here are a few parameters that you might want to tune:\n",
    "\n",
    "- **stop_words:** string {'english'}, list, or None (default)\n",
    "    - If 'english', a built-in stop word list for English is used.\n",
    "    - If a list, that list is assumed to contain stop words, all of which will be removed from the resulting tokens.\n",
    "    - If None, no stop words will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# remove English stop words\n",
    "vect = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "- **ngram_range:** tuple (min_n, max_n), default=(1, 1)\n",
    "    - The lower and upper boundary of the range of n-values for different n-grams to be extracted.\n",
    "    - All values of n such that min_n <= n <= max_n will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# include 1-grams and 2-grams\n",
    "vect = CountVectorizer(ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "- **max_df:** float in range [0.0, 1.0] or int, default=1.0\n",
    "    - When building the vocabulary, ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words).\n",
    "    - If float, the parameter represents a proportion of documents.\n",
    "    - If integer, the parameter represents an absolute count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# ignore terms that appear in more than 50% of the documents\n",
    "vect = CountVectorizer(max_df=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "- **min_df:** float in range [0.0, 1.0] or int, default=1\n",
    "    - When building the vocabulary, ignore terms that have a document frequency strictly lower than the given threshold. (This value is also called \"cut-off\" in the literature.)\n",
    "    - If float, the parameter represents a proportion of documents.\n",
    "    - If integer, the parameter represents an absolute count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# only keep terms that appear in at least 2 documents\n",
    "vect = CountVectorizer(min_df=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "**Guidelines for tuning CountVectorizer:**\n",
    "\n",
    "- Use your knowledge of the **problem** and the **text**, and your understanding of the **tuning parameters**, to help you decide what parameters to tune and how to tune them.\n",
    "\n",
    "Tasks:\n",
    "1. **Experiment**, and let the data tell you the best approach!\n",
    "2. Try to reduce or increase the features and get a better score on the previous model. \n",
    "    * Score above a 99.5%? Tell us! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23230, 2563581)\n",
      "(7744, 2563581)\n",
      "(23230,)\n",
      "(7744,)\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(stop_words='english', ngram_range=(1, 3), max_df=0.5)\n",
    "X_trimmed = vect.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_trimmed, y, random_state=427)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2563581"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tokens = vect.get_feature_names()\n",
    "len(X_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9870    0.9980    0.9925      2974\n",
      "          1     0.9987    0.9918    0.9953      4770\n",
      "\n",
      "avg / total     0.9942    0.9942    0.9942      7744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "print(classification_report(y_test, nb.predict(X_test), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ham_token_count = nb.feature_count_[0, :]\n",
    "spam_token_count = nb.feature_count_[1, :]\n",
    "tokens = pd.DataFrame({'token':X_train_tokens, 'ham':ham_token_count, 'spam':spam_token_count}).set_index('token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "      <th>spam_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hb</th>\n",
       "      <td>1689.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cert</th>\n",
       "      <td>1681.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nil nil</th>\n",
       "      <td>1615.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>handy</th>\n",
       "      <td>1459.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>node</th>\n",
       "      <td>1452.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nodes</th>\n",
       "      <td>1426.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nil nil nil</th>\n",
       "      <td>1369.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>handy board</th>\n",
       "      <td>1308.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>port</th>\n",
       "      <td>1284.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usd edu</th>\n",
       "      <td>1155.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ribbon</th>\n",
       "      <td>1061.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ribbon campaign</th>\n",
       "      <td>1033.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign html</th>\n",
       "      <td>1026.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign html mail</th>\n",
       "      <td>1026.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ribbon campaign html</th>\n",
       "      <td>1026.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ascii ribbon</th>\n",
       "      <td>1017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>output</th>\n",
       "      <td>1017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ascii ribbon campaign</th>\n",
       "      <td>1017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jonathan ascii ribbon</th>\n",
       "      <td>1010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jonathan ascii</th>\n",
       "      <td>1010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robot</th>\n",
       "      <td>993.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>libimlib</th>\n",
       "      <td>865.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linux</th>\n",
       "      <td>851.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>motors</th>\n",
       "      <td>831.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>women studies</th>\n",
       "      <td>799.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thu</th>\n",
       "      <td>766.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>routing</th>\n",
       "      <td>731.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sensor</th>\n",
       "      <td>718.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sep</th>\n",
       "      <td>709.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nil</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.001488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>info hereopt campaign</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1826.0</td>\n",
       "      <td>1826.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hereopt campaign website</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1826.0</td>\n",
       "      <td>1826.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hereopt</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1826.0</td>\n",
       "      <td>1826.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0px padding</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4089.0</td>\n",
       "      <td>2044.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windows xp proms</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2329.0</td>\n",
       "      <td>2329.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>professionaladobe</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2329.0</td>\n",
       "      <td>2329.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xp proms</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2329.0</td>\n",
       "      <td>2329.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proms office 2003</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2329.0</td>\n",
       "      <td>2329.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proms office</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2329.0</td>\n",
       "      <td>2329.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proms</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2329.0</td>\n",
       "      <td>2329.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xp proms office</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2329.0</td>\n",
       "      <td>2329.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price 69 95</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2329.0</td>\n",
       "      <td>2329.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price 69</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2329.0</td>\n",
       "      <td>2329.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69 95 add</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2329.0</td>\n",
       "      <td>2329.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium border medium</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2329.0</td>\n",
       "      <td>2329.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium border</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2329.0</td>\n",
       "      <td>2329.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>border medium</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2329.0</td>\n",
       "      <td>2329.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>info microsoft</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2329.0</td>\n",
       "      <td>2329.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left 0px padding</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2337.0</td>\n",
       "      <td>2337.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69 95</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2559.0</td>\n",
       "      <td>2559.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0px</th>\n",
       "      <td>4.0</td>\n",
       "      <td>10541.0</td>\n",
       "      <td>2635.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ddd 1px solid</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2911.0</td>\n",
       "      <td>2911.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ddd 1px</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2911.0</td>\n",
       "      <td>2911.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>padding left 0px</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2919.0</td>\n",
       "      <td>2919.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left 0px</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2923.0</td>\n",
       "      <td>2923.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15px</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2923.0</td>\n",
       "      <td>2923.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95 add cart</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3493.0</td>\n",
       "      <td>3493.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95 add</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3493.0</td>\n",
       "      <td>3493.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>add cart</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3493.0</td>\n",
       "      <td>3493.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_table</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9296.0</td>\n",
       "      <td>9296.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2563581 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             ham     spam   spam_ratio\n",
       "token                                                 \n",
       "hb                        1689.0      1.0     0.000592\n",
       "cert                      1681.0      1.0     0.000595\n",
       "nil nil                   1615.0      1.0     0.000619\n",
       "handy                     1459.0      1.0     0.000685\n",
       "node                      1452.0      1.0     0.000689\n",
       "nodes                     1426.0      1.0     0.000701\n",
       "nil nil nil               1369.0      1.0     0.000730\n",
       "handy board               1308.0      1.0     0.000765\n",
       "port                      1284.0      1.0     0.000779\n",
       "usd edu                   1155.0      1.0     0.000866\n",
       "ribbon                    1061.0      1.0     0.000943\n",
       "ribbon campaign           1033.0      1.0     0.000968\n",
       "campaign html             1026.0      1.0     0.000975\n",
       "campaign html mail        1026.0      1.0     0.000975\n",
       "ribbon campaign html      1026.0      1.0     0.000975\n",
       "ascii ribbon              1017.0      1.0     0.000983\n",
       "output                    1017.0      1.0     0.000983\n",
       "ascii ribbon campaign     1017.0      1.0     0.000983\n",
       "jonathan ascii ribbon     1010.0      1.0     0.000990\n",
       "jonathan ascii            1010.0      1.0     0.000990\n",
       "robot                      993.0      1.0     0.001007\n",
       "libimlib                   865.0      1.0     0.001156\n",
       "linux                      851.0      1.0     0.001175\n",
       "motors                     831.0      1.0     0.001203\n",
       "women studies              799.0      1.0     0.001252\n",
       "thu                        766.0      1.0     0.001305\n",
       "routing                    731.0      1.0     0.001368\n",
       "sensor                     718.0      1.0     0.001393\n",
       "sep                        709.0      1.0     0.001410\n",
       "nil                       2016.0      3.0     0.001488\n",
       "...                          ...      ...          ...\n",
       "info hereopt campaign        1.0   1826.0  1826.000000\n",
       "hereopt campaign website     1.0   1826.0  1826.000000\n",
       "hereopt                      1.0   1826.0  1826.000000\n",
       "0px padding                  2.0   4089.0  2044.500000\n",
       "windows xp proms             1.0   2329.0  2329.000000\n",
       "professionaladobe            1.0   2329.0  2329.000000\n",
       "xp proms                     1.0   2329.0  2329.000000\n",
       "proms office 2003            1.0   2329.0  2329.000000\n",
       "proms office                 1.0   2329.0  2329.000000\n",
       "proms                        1.0   2329.0  2329.000000\n",
       "xp proms office              1.0   2329.0  2329.000000\n",
       "price 69 95                  1.0   2329.0  2329.000000\n",
       "price 69                     1.0   2329.0  2329.000000\n",
       "69 95 add                    1.0   2329.0  2329.000000\n",
       "medium border medium         1.0   2329.0  2329.000000\n",
       "medium border                1.0   2329.0  2329.000000\n",
       "border medium                1.0   2329.0  2329.000000\n",
       "info microsoft               1.0   2329.0  2329.000000\n",
       "left 0px padding             1.0   2337.0  2337.000000\n",
       "69 95                        1.0   2559.0  2559.000000\n",
       "0px                          4.0  10541.0  2635.250000\n",
       "ddd 1px solid                1.0   2911.0  2911.000000\n",
       "ddd 1px                      1.0   2911.0  2911.000000\n",
       "padding left 0px             1.0   2919.0  2919.000000\n",
       "left 0px                     1.0   2923.0  2923.000000\n",
       "15px                         1.0   2923.0  2923.000000\n",
       "95 add cart                  1.0   3493.0  3493.000000\n",
       "95 add                       1.0   3493.0  3493.000000\n",
       "add cart                     1.0   3493.0  3493.000000\n",
       "product_table                1.0   9296.0  9296.000000\n",
       "\n",
       "[2563581 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['ham'] = tokens.ham + 1\n",
    "tokens['spam'] = tokens.spam + 1\n",
    "tokens['spam_ratio'] = tokens.spam / tokens.ham\n",
    "tokens.sort_values('spam_ratio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 10: Tuning the Laplacian Correction Factor (Challenge)\n",
    "\n",
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html):\n",
    "\n",
    "> class sklearn.naive_bayes.MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None)\n",
    "\n",
    "> Parameters:\t\n",
    "alpha : float, optional (default=1.0)\n",
    "Additive (Laplace/Lidstone) smoothing parameter (0 for no smoothing).\n",
    "\n",
    "One of the parameters that we can tune in training a Multinomial Naive Bayes Classifier is the Laplacian Correction Factor.\n",
    "\n",
    "Tasks:\n",
    "1. Tweak the correction factor from 0-3 in increments of 0.1, 5, and 10, thus training multiple classifiers.\n",
    "2. Plot the precision-recall curves for these classifiers to compare and contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [MultinomialNB(alpha=i) for i in np.concatenate((np.arange(0, 3.1, 0.1), [5, 10]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hadrianpaulo/anaconda/lib/python3.5/site-packages/sklearn/naive_bayes.py:699: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = (np.log(smoothed_fc) -\n"
     ]
    }
   ],
   "source": [
    "for i in classifiers:\n",
    "    i.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116ba02b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "for i in classifiers:\n",
    "    precision, recall, _ = precision_recall_curve(y_test.ravel(),\n",
    "        i.predict(X_test).ravel())\n",
    "    average_precision = average_precision_score(y_test, i.predict(X_test).ravel(),\n",
    "                                                         average=\"micro\")\n",
    "    plot(recall, precision,\n",
    "             label='micro-average Precision-recall curve (area = {0:0.2f})'\n",
    "                   ''.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.8966    0.9997    0.9453      2974\n",
      "          1     0.9998    0.9281    0.9626      4770\n",
      "\n",
      "avg / total     0.9601    0.9556    0.9560      7744\n",
      "\n",
      "0.1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9880    0.9987    0.9933      2974\n",
      "          1     0.9992    0.9925    0.9958      4770\n",
      "\n",
      "avg / total     0.9949    0.9948    0.9948      7744\n",
      "\n",
      "0.2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9877    0.9983    0.9930      2974\n",
      "          1     0.9989    0.9922    0.9956      4770\n",
      "\n",
      "avg / total     0.9946    0.9946    0.9946      7744\n",
      "\n",
      "0.3\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9877    0.9983    0.9930      2974\n",
      "          1     0.9989    0.9922    0.9956      4770\n",
      "\n",
      "avg / total     0.9946    0.9946    0.9946      7744\n",
      "\n",
      "0.4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9877    0.9983    0.9930      2974\n",
      "          1     0.9989    0.9922    0.9956      4770\n",
      "\n",
      "avg / total     0.9946    0.9946    0.9946      7744\n",
      "\n",
      "0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9877    0.9983    0.9930      2974\n",
      "          1     0.9989    0.9922    0.9956      4770\n",
      "\n",
      "avg / total     0.9946    0.9946    0.9946      7744\n",
      "\n",
      "0.6\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9874    0.9983    0.9928      2974\n",
      "          1     0.9989    0.9920    0.9955      4770\n",
      "\n",
      "avg / total     0.9945    0.9944    0.9945      7744\n",
      "\n",
      "0.7\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9874    0.9983    0.9928      2974\n",
      "          1     0.9989    0.9920    0.9955      4770\n",
      "\n",
      "avg / total     0.9945    0.9944    0.9945      7744\n",
      "\n",
      "0.8\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9870    0.9980    0.9925      2974\n",
      "          1     0.9987    0.9918    0.9953      4770\n",
      "\n",
      "avg / total     0.9942    0.9942    0.9942      7744\n",
      "\n",
      "0.9\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9870    0.9980    0.9925      2974\n",
      "          1     0.9987    0.9918    0.9953      4770\n",
      "\n",
      "avg / total     0.9942    0.9942    0.9942      7744\n",
      "\n",
      "1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9870    0.9980    0.9925      2974\n",
      "          1     0.9987    0.9918    0.9953      4770\n",
      "\n",
      "avg / total     0.9942    0.9942    0.9942      7744\n",
      "\n",
      "1.1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9864    0.9976    0.9920      2974\n",
      "          1     0.9985    0.9914    0.9950      4770\n",
      "\n",
      "avg / total     0.9939    0.9938    0.9938      7744\n",
      "\n",
      "1.2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9864    0.9976    0.9920      2974\n",
      "          1     0.9985    0.9914    0.9950      4770\n",
      "\n",
      "avg / total     0.9939    0.9938    0.9938      7744\n",
      "\n",
      "1.3\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9864    0.9976    0.9920      2974\n",
      "          1     0.9985    0.9914    0.9950      4770\n",
      "\n",
      "avg / total     0.9939    0.9938    0.9938      7744\n",
      "\n",
      "1.4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9864    0.9976    0.9920      2974\n",
      "          1     0.9985    0.9914    0.9950      4770\n",
      "\n",
      "avg / total     0.9939    0.9938    0.9938      7744\n",
      "\n",
      "1.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9870    0.9976    0.9923      2974\n",
      "          1     0.9985    0.9918    0.9952      4770\n",
      "\n",
      "avg / total     0.9941    0.9941    0.9941      7744\n",
      "\n",
      "1.6\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9867    0.9976    0.9921      2974\n",
      "          1     0.9985    0.9916    0.9951      4770\n",
      "\n",
      "avg / total     0.9940    0.9939    0.9939      7744\n",
      "\n",
      "1.7\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9867    0.9973    0.9920      2974\n",
      "          1     0.9983    0.9916    0.9950      4770\n",
      "\n",
      "avg / total     0.9938    0.9938    0.9938      7744\n",
      "\n",
      "1.8\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9860    0.9973    0.9916      2974\n",
      "          1     0.9983    0.9912    0.9947      4770\n",
      "\n",
      "avg / total     0.9936    0.9935    0.9936      7744\n",
      "\n",
      "1.9\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9860    0.9973    0.9916      2974\n",
      "          1     0.9983    0.9912    0.9947      4770\n",
      "\n",
      "avg / total     0.9936    0.9935    0.9936      7744\n",
      "\n",
      "2.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9854    0.9973    0.9913      2974\n",
      "          1     0.9983    0.9908    0.9945      4770\n",
      "\n",
      "avg / total     0.9933    0.9933    0.9933      7744\n",
      "\n",
      "2.1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9854    0.9973    0.9913      2974\n",
      "          1     0.9983    0.9908    0.9945      4770\n",
      "\n",
      "avg / total     0.9933    0.9933    0.9933      7744\n",
      "\n",
      "2.2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9851    0.9973    0.9911      2974\n",
      "          1     0.9983    0.9906    0.9944      4770\n",
      "\n",
      "avg / total     0.9932    0.9932    0.9932      7744\n",
      "\n",
      "2.3\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9851    0.9973    0.9911      2974\n",
      "          1     0.9983    0.9906    0.9944      4770\n",
      "\n",
      "avg / total     0.9932    0.9932    0.9932      7744\n",
      "\n",
      "2.4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9851    0.9973    0.9911      2974\n",
      "          1     0.9983    0.9906    0.9944      4770\n",
      "\n",
      "avg / total     0.9932    0.9932    0.9932      7744\n",
      "\n",
      "2.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9847    0.9973    0.9910      2974\n",
      "          1     0.9983    0.9904    0.9943      4770\n",
      "\n",
      "avg / total     0.9931    0.9930    0.9930      7744\n",
      "\n",
      "2.6\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9847    0.9973    0.9910      2974\n",
      "          1     0.9983    0.9904    0.9943      4770\n",
      "\n",
      "avg / total     0.9931    0.9930    0.9930      7744\n",
      "\n",
      "2.7\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9847    0.9973    0.9910      2974\n",
      "          1     0.9983    0.9904    0.9943      4770\n",
      "\n",
      "avg / total     0.9931    0.9930    0.9930      7744\n",
      "\n",
      "2.8\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9847    0.9973    0.9910      2974\n",
      "          1     0.9983    0.9904    0.9943      4770\n",
      "\n",
      "avg / total     0.9931    0.9930    0.9930      7744\n",
      "\n",
      "2.9\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9847    0.9973    0.9910      2974\n",
      "          1     0.9983    0.9904    0.9943      4770\n",
      "\n",
      "avg / total     0.9931    0.9930    0.9930      7744\n",
      "\n",
      "3.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9847    0.9966    0.9906      2974\n",
      "          1     0.9979    0.9904    0.9941      4770\n",
      "\n",
      "avg / total     0.9928    0.9928    0.9928      7744\n",
      "\n",
      "5.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9837    0.9966    0.9901      2974\n",
      "          1     0.9979    0.9897    0.9938      4770\n",
      "\n",
      "avg / total     0.9925    0.9924    0.9924      7744\n",
      "\n",
      "10.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9802    0.9966    0.9883      2974\n",
      "          1     0.9979    0.9874    0.9926      4770\n",
      "\n",
      "avg / total     0.9911    0.9910    0.9910      7744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in classifiers:\n",
    "    print(i.get_params()['alpha'])\n",
    "    print(classification_report(y_test, i.predict(X_test),digits=4))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
